# SPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

name: PR

on:
  push:
    branches:
      - main
      - "pull-request/[0-9]+"
      # Note: release/* branches are handled by release.yml workflow
  # TEMPORARY: Add pull_request trigger for testing
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      run_deploy_operator:
        description: 'Run deploy operator and deployment tests'
        required: false
        type: boolean
        default: false

concurrency:
    # The group name is a ternary operation. If the ref_name is 'main',
    # then the group name uses the run_id to ensure a unique group for
    # 'main' pushes. Otherwise, the group name is the ref_name, so that
    # workflows on the same PR/branch have the same group name for cancelling.
    group: docker-build-test-${{ github.ref_name == 'main' && github.run_id || github.ref_name }}
    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

env:
  BUILDER_NAME: b-${{ github.run_id }}-${{ github.run_attempt }}

jobs:

  # ============================================================================
  # SETUP & DETECTION JOBS
  # ============================================================================


  changed-files:
    runs-on: ubuntu-latest
    environment: ${{ github.event_name == 'workflow_dispatch' && 'protected-deploy' || '' }}
    outputs:
      core: ${{ steps.changes.outputs.core }}
      operator: ${{ steps.changes.outputs.operator }}
      deploy: ${{ steps.changes.outputs.deploy }}
      vllm: ${{ steps.changes.outputs.vllm }}
      sglang: ${{ steps.changes.outputs.sglang }}
      trtllm: ${{ steps.changes.outputs.trtllm }}
      builder_name: ${{ steps.export-builder-name.outputs.builder_name }}
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
        with:
          fetch-depth: 0
      - name: Check for changes
        id: changes
        uses: ./.github/actions/changed-files
        with:
          gh_token: ${{ github.token }}
      - name: Export builder name
        id: export-builder-name
        run: |
          echo "builder_name=${{ env.BUILDER_NAME }}" >> $GITHUB_OUTPUT

  # TEMPORARY: Quick OpenSearch connectivity test
  test-opensearch-connectivity:
    name: Test OpenSearch Connection
    runs-on: gitlab
    timeout-minutes: 2
    steps:
      - name: Test OpenSearch connectivity
        run: |
          echo "Testing OpenSearch connectivity..."
          OPENSEARCH_ENDPOINT="https://gpuwa.nvidia.com/opensearch/df-swdl-triton-ops-gh-tests*"

          if curl -s --max-time 5 "$OPENSEARCH_ENDPOINT" > /dev/null 2>&1; then
            echo "âœ… OpenSearch is reachable from gitlab runner"
            exit 0
          else
            echo "âš ï¸ OpenSearch is NOT reachable from gitlab runner"
            echo "Flaky detection will work but categorize all tests as legitimate failures"
            exit 0
          fi

  # TEMPORARY: Flaky test detection for testing
  flaky-test-detection:
    name: Flaky Test Detection
    runs-on: gitlab
    timeout-minutes: 15
    if: always()
    needs: [vllm, sglang, trtllm, test-opensearch-connectivity]
    permissions:
      contents: read
      actions: read
    env:
      OPENSEARCH_ENDPOINT: https://gpuwa.nvidia.com/opensearch/df-swdl-triton-ops-gh-tests*
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL }}
      SLACK_OPS_GROUP_ID: ${{ secrets.SLACK_OPS_SUPPORT_GROUP_ID }}
      FLAKY_THRESHOLD: "0.80"
      LOOKBACK_DAYS: "7"
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0

      - name: Download test artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-results/
          pattern: test-results-*

      - name: Setup Python environment
        run: |
          sudo apt-get update && sudo apt-get install -y python3-venv || true
          python3 -m venv venv
          source venv/bin/activate
          pip install requests

      - name: Detect flaky tests
        id: detect_flaky
        continue-on-error: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          WORKFLOW_NAME: ${{ github.workflow }}
        run: |
          source venv/bin/activate
          python3 .github/workflows/detect_flaky_tests.py

      - name: Report status
        if: always()
        run: |
          if [ "${{ steps.detect_flaky.outcome }}" == "success" ]; then
            echo "âœ… Flaky test detection completed successfully"
          else
            echo "âš ï¸ Flaky test detection encountered errors, check logs"
          fi

  backend-status-check:
    runs-on: ubuntu-latest
    needs: [changed-files, vllm, sglang, trtllm, operator]  # THIS list determines blocking jobs
    if: always()
    steps:
      - name: "Check all dependent jobs"
        run: |
          echo '${{ toJson(needs) }}' | jq -e 'to_entries | map(.value.result) | all(. as $result | ["success", "skipped"] | any($result == .))'


  # ============================================================================
  # Operator
  # ============================================================================

  operator:
    needs: changed-files
    # TEMPORARY: Skip operator on flaky-tests branch for quick testing
    if: needs.changed-files.outputs.operator == 'true' && !contains(github.head_ref, 'flaky-tests')
    strategy:
      fail-fast: false
      matrix:
        platform:
          - { arch: amd64, runner: prod-builder-amd-v1 }
          - { arch: arm64, runner: prod-builder-arm-v1 }
    name: operator-build (${{ matrix.platform.arch }})
    runs-on: ${{ matrix.platform.runner }}
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
      - name: Initialize Dynamo Builder
        uses: ./.github/actions/init-dynamo-builder
        with:
          builder_name: ${{ needs.changed-files.outputs.builder_name }}
          flavor: general
          all_arch: 'true'
      - name: Docker Login
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}
      - name: Linter
        shell: bash
        working-directory: ./deploy/operator
        run: |
          docker buildx build --platform linux/arm64 --target linter --progress=plain --build-arg DOCKER_PROXY=${ECR_HOSTNAME}/dockerhub/ .
      - name: Tester
        shell: bash
        working-directory: ./deploy/operator
        run: |
          docker buildx build --platform linux/arm64 --target tester --progress=plain --build-arg DOCKER_PROXY=${ECR_HOSTNAME}/dockerhub/ .
      - name: Set up Go
        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0
        with:
          go-version: '1.25'
      - name: Check for uncommitted changes
        shell: bash
        working-directory: ./deploy/operator
        run: |
          make check
      - name: Build and push Container
        id: build-and-push-image
        shell: bash
        working-directory: ./deploy/operator
        env:
          NO_CACHE_FLAG: '' # placeholder for future logic to add no cache flag if needed
        run: |
          ECR_DEFAULT_IMAGE_BASE="${ECR_HOSTNAME}/${IMAGE_REGISTRY}/${IMAGE_REPOSITORY}"
          DEFAULT_TAG="${{ github.sha }}-operator"
          ACR_IMAGE_BASE="${{ secrets.AZURE_ACR_HOSTNAME }}/${IMAGE_REGISTRY}/${IMAGE_REPOSITORY}"
          IMAGE_URIS=(
            "${ECR_DEFAULT_IMAGE_BASE}:${DEFAULT_TAG}"
            "${ACR_IMAGE_BASE}:${DEFAULT_TAG}"
          )

          if [[ "${{ github.ref_name }}" == "main" ]]; then
            IMAGE_URIS+=(
              "${ECR_DEFAULT_IMAGE_BASE}:main-operator"
              "${ACR_IMAGE_BASE}:main-operator"
            )
          fi

          echo "operator_default_tag=${DEFAULT_TAG}" >> $GITHUB_OUTPUT
          TAGGING_FLAGS=$(printf -- '-t %s ' "${IMAGE_URIS[@]}")
          echo "flags for docker buildx: ${TAGGING_FLAGS}"

          if [[ "$NO_CACHE_FLAG" == "true" ]]; then
            NO_CACHE_FLAG="--no-cache"
          fi
          docker buildx build --push ${NO_CACHE_FLAG} \
              --platform linux/amd64,linux/arm64 \
              --build-arg DOCKER_PROXY=${ECR_HOSTNAME}/dockerhub/ \
              ${TAGGING_FLAGS} -f Dockerfile .

  vllm:
    needs: changed-files
    if: needs.changed-files.outputs.core == 'true' || needs.changed-files.outputs.vllm == 'true'
    strategy:
      fail-fast: false
      matrix:
        platform:
          - { arch: amd64, runner: prod-builder-amd-gpu-v1 }
          - { arch: arm64, runner: prod-builder-arm-v1 }
        cuda_version:
          - { major_minor: '13.0', major: '13' }
          - { major_minor: '12.9', major: '12' }
    name: vllm-build-test (cuda${{ matrix.cuda_version.major_minor}}, ${{ matrix.platform.arch }})
    runs-on: ${{ matrix.platform.runner }}
    timeout-minutes: 240
    env:
      FRAMEWORK: vllm
    steps: &runtime-container-build-push-test
      - name: Output Node Name
        shell: bash
        run: |
          echo ${K8S_NODE_NAME}
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
        with:
          lfs: true
      - name: Docker Login
        uses: ./.github/actions/docker-login
        with:
          ngc_ci_access_token: ${{ secrets.NGC_CI_ACCESS_TOKEN }}
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}
      - name: Build Container
        id: build-image
        uses: ./.github/actions/docker-build
        with:
          framework: ${{ env.FRAMEWORK }}
          target: runtime
          platform: 'linux/${{ matrix.platform.arch }}'
          cuda_version: ${{ matrix.cuda_version.major_minor }}
          ci_token: ${{ secrets.CI_TOKEN }}
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          sccache_s3_bucket: ${{ secrets.SCCACHE_S3_BUCKET }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      - name: Docker Tag and Push
        uses: ./.github/actions/docker-tag-push
        with:
          local_image: ${{ steps.build-image.outputs.image_tag }}
          push_tags: |
            ai-dynamo/dynamo:${{ github.sha }}-${{ env.FRAMEWORK }}-${{ matrix.platform.arch }}
            ai-dynamo/dynamo:${{ github.sha }}-${{ env.FRAMEWORK }}-cuda${{ matrix.cuda_version.major }}-${{ matrix.platform.arch }}
          conditional_tag: ${{ github.ref_name == 'main' && format('ai-dynamo/dynamo:main-{0}-cuda{1}-{2}', env.FRAMEWORK, matrix.cuda_version.major, matrix.platform.arch) || '' }}
          aws_push: 'true'
          azure_push: 'true'
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
      - name: Run tests
        # TODO: enable testing on ARM when these tests stop failing on collection on machines without GPUs:
        #   components/src/dynamo/trtllm/tests/test_trtllm_autodeploy.py
        #   components/src/dynamo/trtllm/tests/test_trtllm_unit.py
        if: ${{ env.FRAMEWORK != 'trtllm' || matrix.platform.arch == 'amd64' }} # Excludes trtllm on arm64
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ steps.build-image.outputs.image_tag }}
          # GH ARM runners have no GPUs, run CPU tests only on ARM
          pytest_marks: ${{ matrix.platform.arch == 'amd64' && format('pre_merge and {0} and (gpu_0 or gpu_1)', env.FRAMEWORK) || format('pre_merge and {0} and gpu_0', env.FRAMEWORK) }}
          framework: ${{ env.FRAMEWORK }}
          test_type: "pre_merge"
          platform_arch: ${{ matrix.platform.arch }}
          enable_mypy: 'true'
          hf_token: ${{ secrets.HF_TOKEN }}

  sglang:
    needs: changed-files
    # TEMPORARY: Skip sglang on flaky-tests branch for quick testing
    if: (needs.changed-files.outputs.core == 'true' || needs.changed-files.outputs.sglang == 'true') && !contains(github.head_ref, 'flaky-tests')
    strategy:
      fail-fast: false
      matrix:
        platform:
          - { arch: amd64, runner: prod-builder-amd-gpu-v1 }
          - { arch: arm64, runner: prod-builder-arm-v1 }
        cuda_version:
          - { major_minor: '13.0', major: '13' }
          - { major_minor: '12.9', major: '12' }
    name: sglang-build-test (cuda${{ matrix.cuda_version.major_minor}}, ${{ matrix.platform.arch }})
    runs-on: ${{ matrix.platform.runner }}
    timeout-minutes: 90
    env:
      FRAMEWORK: sglang
    steps: *runtime-container-build-push-test

  trtllm:
    needs: changed-files
    # TEMPORARY: Skip trtllm on flaky-tests branch for quick testing
    if: (needs.changed-files.outputs.core == 'true' || needs.changed-files.outputs.trtllm == 'true') && !contains(github.head_ref, 'flaky-tests')
    strategy:
      fail-fast: false
      matrix:
        platform:
          - { arch: amd64, runner: prod-builder-amd-gpu-v1 }
          - { arch: arm64, runner: prod-builder-arm-v1 }
        cuda_version:
          - { major_minor: '13.1', major: '13' }
    name: trtllm-build-test (cuda${{ matrix.cuda_version.major_minor}}, ${{ matrix.platform.arch }})
    runs-on: ${{ matrix.platform.runner }}
    timeout-minutes: 90
    env:
      FRAMEWORK: trtllm
    steps: *runtime-container-build-push-test

  deploy-operator:
    runs-on: prod-default-small-v2
    if: needs.changed-files.outputs.core == 'true'
    needs: [changed-files, operator]
    outputs:
      NAMESPACE: ${{ steps.deploy-operator-step.outputs.namespace }}
    steps:
    - uses: actions/checkout@v4
    - name: Deploy Operator
      id: deploy-operator-step
      env:
        BRANCH: ${{ github.ref_name }}
      run: |
        set -x

        # Set namespace
        # Invalid patterns: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/
        BRANCH_SANITIZED="${BRANCH//\//-}"
        BRANCH_SANITIZED="${BRANCH_SANITIZED/pull-request/pr}"
        BRANCH_SANITIZED="${BRANCH_SANITIZED//./-}"
        # Cap at 10 chars
        BRANCH_SANITIZED="${BRANCH_SANITIZED:0:10}"
        NAMESPACE="gh-id-${{ github.run_id }}-${BRANCH_SANITIZED}-dt"
        echo "namespace=${NAMESPACE}" >> "$GITHUB_OUTPUT"

        # Setup kubeconfig
        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
        chmod 600 .kubeconfig
        export KUBECONFIG=$(pwd)/.kubeconfig
        kubectl config set-context --current --namespace=$NAMESPACE --kubeconfig "${KUBECONFIG}"
        kubectl config current-context

        # Create a namespace for this job
        echo "Creating an ephemeral namespace..."
        kubectl create namespace $NAMESPACE
        echo "Attaching the labels for secrets and cleanup"
        kubectl label namespaces ${NAMESPACE} nscleanup/enabled=true nscleanup/ttl=7200 gitlab-imagepull=enabled ngc-api=enabled nvcr-imagepull=enabled --overwrite=true

        # Set the namespace as default
        kubectl config set-context --current --namespace=$NAMESPACE

        # Check if Istio is installed
        kubectl get pods -n istio-system
        # Check if default storage class exists
        kubectl get storageclass

        # Install Helm chart
        export VIRTUAL_ENV=/opt/dynamo/venv
        export KUBE_NS=$NAMESPACE
        export ISTIO_ENABLED=true
        export ISTIO_GATEWAY=istio-system/ingress-alb
        export VIRTUAL_SERVICE_SUPPORTS_HTTPS=true

        # Install dynamo env secrets
        kubectl create secret generic hf-token-secret --from-literal=HF_TOKEN=${{ secrets.HF_TOKEN }} -n $KUBE_NS || true
        # Install helm dependencies
        helm repo add bitnami https://charts.bitnami.com/bitnami
        cd deploy/helm/charts/platform/
        helm dep build .
        # Install platform with namespace restriction for single profile testing
        helm upgrade --install dynamo-platform . --namespace ${NAMESPACE} \
          --set dynamo-operator.namespaceRestriction.enabled=true \
          --set dynamo-operator.namespaceRestriction.allowedNamespaces[0]=${NAMESPACE} \
          --set dynamo-operator.controllerManager.manager.image.repository=${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo \
          --set dynamo-operator.controllerManager.manager.image.tag=${{ needs.operator.outputs.operator_default_tag }} \
          --set dynamo-operator.imagePullSecrets[0].name=docker-imagepullsecret
        # Wait for all deployments to be ready
        timeout 300s kubectl rollout status deployment -n $NAMESPACE --watch
    - name: ðŸ” Report Unhealthy Pods
      if: failure()
      run: |
        # Setup kubeconfig
        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
        chmod 600 .kubeconfig
        export KUBECONFIG=$(pwd)/.kubeconfig
        kubectl config set-context --current --namespace=$NAMESPACE --kubeconfig "${KUBECONFIG}"
        kubectl config current-context
        # Descriptive header for the summary
        echo "### âš ï¸ OPERATOR DEPLOYMENT FAILED: Unhealthy Pods Report" >> $GITHUB_STEP_SUMMARY
        echo "Unhealthy pods:" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        # Get pods, exclude healthy ones, and format output
        # If the namespace is empty or all pods are healthy, the grep/awk won't output anything, which is handled gracefully.
        kubectl get pods -n ${{ steps.deploy-operator-step.outputs.namespace }} --no-headers \
          | grep -v -E '(Running|Completed)' \
          | awk '{print "- ðŸ”´ **" $1 "** | Status: `" $3 "`"}' >> $GITHUB_STEP_SUMMARY || true

   # ============================================================================
   #
   # End-to-end tests for each framework with various deployment profiles
   # ============================================================================
  deploy-test-vllm:
    if: ( github.ref_name == 'main' || github.event.inputs.run_deploy_operator )
    runs-on: prod-default-small-v2
    needs: [deploy-operator, vllm]
    permissions:
      contents: read
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        profile:
          - agg
          - agg_router
          - disagg
          # - disagg_router
    name: deploy-test-vllm (${{ matrix.profile }})
    env:
      FRAMEWORK: vllm
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
      - name: Run Dynamo Deploy Test
        id: deploy-test
        uses: ./.github/actions/dynamo-deploy-test
        with:
          kubeconfig_base64: ${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}
          namespace: ${{ needs.deploy-operator.outputs.NAMESPACE }}
          deployment_file: "deploy/${{ matrix.profile }}.yaml"
          framework: ${{ env.FRAMEWORK }}
          framework_runtime_image: ${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:${{ github.sha }}-vllm-cuda12-amd64
          model_name: "Qwen/Qwen3-0.6B"
          test_identifier: ${{ env.FRAMEWORK }}_${{ matrix.profile }}_amd64_${{ github.run_id }}_${{ github.run_attempt }}



  # For now, this job is separated from the job matrix above for easier flow control handling
  # Uncomment the disagg_router matrix entry from the above job and delete the below job
  # when we want to run them under the same conditions.
  # Current conditions:
  # - Run vllm disagg_router on all commits
  # - Run rest of jobs only on push to main or manual trigger
  deploy-test-vllm-disagg-router:
    runs-on:  prod-default-small-v2
    if: needs.changed-files.outputs.core == 'true' || needs.changed-files.outputs.vllm == 'true' || needs.changed-files.outputs.deploy == 'true'
    needs: [changed-files, deploy-operator, vllm]
    permissions:
      contents: read
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        profile:
          - disagg_router
    name: deploy-test-vllm (${{ matrix.profile }})
    env:
      FRAMEWORK: vllm
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
      - name: Run Dynamo Deploy Test
        id: deploy-test
        uses: ./.github/actions/dynamo-deploy-test
        with:
          kubeconfig_base64: ${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}
          namespace: ${{ needs.deploy-operator.outputs.NAMESPACE }}
          deployment_file: "deploy/${{ matrix.profile }}.yaml"
          framework: ${{ env.FRAMEWORK }}
          framework_runtime_image: ${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:${{ github.sha }}-vllm-cuda12-amd64
          model_name: "Qwen/Qwen3-0.6B"
          test_identifier: ${{ env.FRAMEWORK }}_${{ matrix.profile }}_amd64_${{ github.run_id }}_${{ github.run_attempt }}


  deploy-test-sglang:
    runs-on: prod-default-small-v2
    # Run if push to main, or manually triggered
    if: ( github.ref_name == 'main' || github.event.inputs.run_deploy_operator )
    needs: [changed-files, deploy-operator, sglang]
    permissions:
      contents: read
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        profile:
          - agg
          - agg_router
    name: deploy-test-sglang (${{ matrix.profile }})
    env:
      FRAMEWORK: sglang
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
      - name: Run Dynamo Deploy Test
        id: deploy-test
        uses: ./.github/actions/dynamo-deploy-test
        with:
          kubeconfig_base64: ${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}
          namespace: ${{ needs.deploy-operator.outputs.NAMESPACE }}
          deployment_file: "deploy/${{ matrix.profile }}.yaml"
          framework: ${{ env.FRAMEWORK }}
          framework_runtime_image: ${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:${{ github.sha }}-sglang-cuda12-amd64
          model_name: "Qwen/Qwen3-0.6B"
          test_identifier: ${{ env.FRAMEWORK }}_${{ matrix.profile }}_amd64_${{ github.run_id }}_${{ github.run_attempt }}


  deploy-test-trtllm:
    runs-on: prod-default-small-v2
    # Run if push to main, or manually triggered
    if: ( github.ref_name == 'main' || github.event.inputs.run_deploy_operator )
    needs: [changed-files, deploy-operator, trtllm]
    permissions:
      contents: read
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        profile:
          - agg
          - agg_router
          - disagg
          - disagg_router
    name: deploy-test-trtllm (${{ matrix.profile }})
    env:
      FRAMEWORK: trtllm
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
      - name: Run Dynamo Deploy Test
        id: deploy-test
        uses: ./.github/actions/dynamo-deploy-test
        with:
          kubeconfig_base64: ${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}
          namespace: ${{ needs.deploy-operator.outputs.NAMESPACE }}
          deployment_file: "deploy/${{ matrix.profile }}.yaml"
          framework: ${{ env.FRAMEWORK }}
          framework_runtime_image: ${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:${{ github.sha }}-trtllm-cuda13-amd64
          model_name: "Qwen/Qwen3-0.6B"
          test_identifier: ${{ env.FRAMEWORK }}_${{ matrix.profile }}_amd64_${{ github.run_id }}_${{ github.run_attempt }}

  # ============================================================================
  # CLEANUP JOBS
  # Clean up ephemeral Kubernetes namespace and resources
  # ============================================================================

  clean-k8s-builder:
    name: Clean K8s builder if exists
    runs-on: prod-default-small-v2
    if: always()
    needs: [vllm, sglang, trtllm, operator, changed-files]
    steps:
    - name: Checkout repository
      uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
    - name: Create K8s builders (skip bootstrap)
      uses: ./.github/actions/bootstrap-buildkit
      continue-on-error: true
      with:
        builder_name: ${{ needs.changed-files.outputs.builder_name }}
        buildkit_worker_addresses: '' # k8s builder
        skip_bootstrap: true
    - name: Builder Cleanup in case of k8s builder
      shell: bash
      run: |
        docker buildx rm ${{ needs.changed-files.outputs.builder_name }} || true


  cleanup:
    name: Cleanup AKS resources
    runs-on: prod-default-small-v2
    if: always()
    needs: [deploy-operator, deploy-test-sglang, deploy-test-trtllm, deploy-test-vllm, deploy-test-vllm-disagg-router]
    steps:
    - name: Checkout code
      uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
    - name: Setup Kubeconfig
      env:
        NAMESPACE: ${{ needs.deploy-operator.outputs.NAMESPACE }}
      run: |
        set -x
        # Setup kubeconfig
        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
        chmod 600 .kubeconfig
        export KUBECONFIG=$(pwd)/.kubeconfig
        kubectl config set-context --current --namespace=$NAMESPACE --kubeconfig "${KUBECONFIG}"
        kubectl config current-context
    - name: Cleanup
      timeout-minutes: 5
      env:
        NAMESPACE: ${{ needs.deploy-operator.outputs.NAMESPACE }}
      run: |
        set -x
        export KUBECONFIG=$(pwd)/.kubeconfig
        kubectl config set-context --current --namespace=$NAMESPACE

        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
        chmod 600 .kubeconfig
        export KUBECONFIG=$(pwd)/.kubeconfig
        kubectl config set-context --current --namespace=$NAMESPACE --kubeconfig "${KUBECONFIG}"

        # For debugging purposes, list all the resources before we uninstall
        kubectl get dynamographdeployments
        kubectl get all

        echo "Deleting all DynamoGraphDeployments in namespace $NAMESPACE..."
        kubectl delete dynamographdeployments --all -n $NAMESPACE || true

        # Uninstall the helm chart
        helm ls
        helm uninstall dynamo-platform --namespace $NAMESPACE --timeout 10m || true

        echo "Namespace $NAMESPACE deletion initiated, proceeding with cleanup..."
        kubectl delete namespace $NAMESPACE || true
        echo "Namespace $NAMESPACE completed."
