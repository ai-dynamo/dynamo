# SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# Reusable CI Test Suite Workflow
# This workflow is called by nightly-ci.yml and post-merge-ci.yml
# to run the full test suite with configurable parameters.

name: CI Test Suite

on:
  workflow_call:
    inputs:
      pipeline_type:
        description: 'Type of pipeline: nightly or post_merge'
        required: true
        type: string
      include_nightly_marks:
        description: 'Include nightly pytest marks in test selection'
        required: true
        type: boolean
      image_prefix:
        description: 'Prefix for image tags (nightly or main)'
        required: true
        type: string
      enable_slack_notification:
        description: 'Enable Slack notifications on completion'
        required: false
        type: boolean
        default: false
      enable_coverage:
        description: 'Enable test coverage collection and reporting'
        required: false
        type: boolean
        default: false
    secrets:
      AWS_ACCOUNT_ID:
        required: true
      AWS_DEFAULT_REGION:
        required: true
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      NGC_CI_ACCESS_TOKEN:
        required: true
      CI_TOKEN:
        required: true
      SCCACHE_S3_BUCKET:
        required: true
      AZURE_ACR_HOSTNAME:
        required: true
      AZURE_ACR_USER:
        required: true
      AZURE_ACR_PASSWORD:
        required: true
      SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL:
        required: false
      SLACK_OPS_SUPPORT_GROUP_ID:
        required: false
      AZURE_AKS_CI_KUBECONFIG_B64:
        required: false
      HF_TOKEN:
        required: false
      DYNAMO_INGRESS_SUFFIX:
        required: false

permissions:
  contents: read

defaults:
  run:
    shell: bash --noprofile --norc -eo pipefail {0}

env:
  REGISTRY_IMAGE: ai-dynamo/dynamo
  IMAGE_PREFIX: ${{ inputs.image_prefix }}

############################## BUILD JOBS ##############################

jobs:
  build-amd64:
    name: Build ${{ matrix.framework }} (amd64)
    runs-on: cpu-amd-m5-4xlarge
    timeout-minutes: 120
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
    env:
      ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
    steps:
      - uses: actions/checkout@v4
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          ngc_ci_access_token: ${{ secrets.NGC_CI_ACCESS_TOKEN }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}
      - name: Pull existing images for cache
        shell: bash
        continue-on-error: true
        run: |
          echo "Attempting to pull existing images for layer caching..."
          docker pull "${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-amd64" || echo "Runtime image not found in cache"
          echo "Cache pull completed"
      - name: Build Runtime Image
        id: build_runtime
        uses: ./.github/actions/docker-build
        with:
          framework: ${{ matrix.framework }}
          target: runtime
          platform: linux/amd64
          base_image_tag: ''
          runtime_image_tag: ''
          cuda_version: ''
          ci_token: ${{ secrets.CI_TOKEN }}
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          sccache_s3_bucket: ${{ secrets.SCCACHE_S3_BUCKET }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          image_tag: runtime-${{ matrix.framework }}-amd64:${{ github.run_id }}
      - name: Tag and Push Runtime Images
        uses: ./.github/actions/docker-tag-push
        with:
          local_image: runtime-${{ matrix.framework }}-amd64:${{ github.run_id }}
          push_tags: |
            ${{ env.REGISTRY_IMAGE }}:${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-amd64
            ${{ env.REGISTRY_IMAGE }}:${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-amd64-run-${{ github.run_id }}
          aws_push: 'true'
          azure_push: 'true'
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}

  build-arm64:
    name: Build ${{ matrix.framework }} (arm64)
    runs-on: cpu-arm-r8g-4xlarge
    timeout-minutes: 120
    strategy:
      fail-fast: false
      matrix:
        include:
          - framework: vllm
            base_image_tag: '25.06-cuda12.9-devel-ubuntu24.04'
            runtime_image_tag: '12.9.0-runtime-ubuntu24.04'
            cuda_version: '12.9'
          - framework: trtllm
            base_image_tag: '25.06-py3'
            runtime_image_tag: ''
            cuda_version: '12.9'
          - framework: sglang
            base_image_tag: ''
            runtime_image_tag: ''
            cuda_version: ''
    env:
      ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
    steps:
      - uses: actions/checkout@v4
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          ngc_ci_access_token: ${{ secrets.NGC_CI_ACCESS_TOKEN }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}
      - name: Pull existing images for cache
        shell: bash
        continue-on-error: true
        run: |
          echo "Attempting to pull existing images for layer caching..."
          docker pull "${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-arm64" || echo "Runtime image not found in cache"
          echo "Cache pull completed"
      - name: Build Runtime Image
        id: build_runtime
        uses: ./.github/actions/docker-build
        with:
          framework: ${{ matrix.framework }}
          target: runtime
          platform: linux/arm64
          base_image_tag: ${{ matrix.base_image_tag }}
          runtime_image_tag: ${{ matrix.runtime_image_tag }}
          cuda_version: ${{ matrix.cuda_version }}
          ci_token: ${{ secrets.CI_TOKEN }}
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          sccache_s3_bucket: ${{ secrets.SCCACHE_S3_BUCKET }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          image_tag: runtime-${{ matrix.framework }}-arm64:${{ github.run_id }}
      - name: Tag and Push Runtime Images
        uses: ./.github/actions/docker-tag-push
        with:
          local_image: runtime-${{ matrix.framework }}-arm64:${{ github.run_id }}
          push_tags: |
            ${{ env.REGISTRY_IMAGE }}:${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-arm64
            ${{ env.REGISTRY_IMAGE }}:${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-arm64-run-${{ github.run_id }}
          aws_push: 'true'
          azure_push: 'true'
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}

############################## TEST JOBS ##############################

  unit-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-unit
    # needs: [build-amd64, build-arm64]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: gpu-l40-amd64
          - arch: arm64
            runner: cpu-arm-r8g-4xlarge
    steps:
      - uses: actions/checkout@v4
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        shell: bash
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run Unit Tests
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
          pytest_marks: ${{ inputs.include_nightly_marks && 'unit and (nightly or post_merge or pre_merge)' || 'unit and (post_merge or pre_merge)' }}
          framework: ${{ matrix.framework }}
          test_type: unit
          platform_arch: ${{ matrix.arch.arch }}
          cpu_limit: '8'
          dry_run: ${{ matrix.arch.arch == 'arm64' && 'true' || 'false' }}
          enable_coverage: ${{ inputs.enable_coverage }}

  integration-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-integ
    # needs: [build-amd64, build-arm64]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: ${{ matrix.arch.timeout }}
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: gpu-l40-amd64
            timeout: 90
          - arch: arm64
            runner: cpu-arm-r8g-4xlarge
            timeout: 90
    steps:
      - uses: actions/checkout@v4
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        shell: bash
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run Integration Tests
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
          pytest_marks: ${{ inputs.include_nightly_marks && 'integration and (nightly or post_merge or pre_merge)' || 'integration and (post_merge or pre_merge)' }}
          framework: ${{ matrix.framework }}
          test_type: integration
          platform_arch: ${{ matrix.arch.arch }}
          dry_run: ${{ matrix.arch.arch == 'arm64' && 'true' || 'false' }}
          enable_coverage: ${{ inputs.enable_coverage }}

  ############################## FAULT TOLERANCE TESTS ##############################

  ############################## COVERAGE REPORT ##############################
  coverage-report:
    name: Generate Coverage Report
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: inputs.enable_coverage && always()
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Coverage Tools
        run: |
          pip install coverage[toml]==7.4.0 pytest-cov
          echo "‚úÖ Coverage tools installed"

      - name: Download All Coverage Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-python-*
          path: coverage-artifacts/
          merge-multiple: false

      - name: List Downloaded Artifacts
        run: |
          echo "üì¶ Downloaded coverage artifacts:"
          find coverage-artifacts/ -type f -name "*.xml" -o -name ".coverage*" | sort

      - name: Merge Coverage by Test Type
        run: |
          set -x
          mkdir -p coverage-by-type

          echo "üìä Processing unit test coverage..."
          find coverage-artifacts/ -path "*-unit-*" -name ".coverage" 2>/dev/null | while read -r file; do
            cp "$file" "coverage-by-type/.coverage.unit.$(basename $(dirname $file))"
          done

          if ls coverage-by-type/.coverage.unit.* 1> /dev/null 2>&1; then
            cd coverage-by-type
            coverage combine .coverage.unit.* --keep
            mv .coverage .coverage.unit
            coverage report --data-file=.coverage.unit > unit-report.txt || echo "No unit coverage data"
            cat unit-report.txt
            cd ..
          else
            echo "No unit test coverage found" > coverage-by-type/unit-report.txt
          fi

          echo "üìä Processing unit + integration test coverage..."
          find coverage-artifacts/ -path "*-unit-*" -o -path "*-integration-*" | grep ".coverage$" 2>/dev/null | while read -r file; do
            cp "$file" "coverage-by-type/.coverage.integration.$(basename $(dirname $file))"
          done

          if ls coverage-by-type/.coverage.integration.* 1> /dev/null 2>&1; then
            cd coverage-by-type
            coverage combine .coverage.integration.* --keep
            mv .coverage .coverage.integration
            coverage report --data-file=.coverage.integration > integration-report.txt || echo "No integration coverage data"
            cat integration-report.txt
            cd ..
          else
            echo "No integration test coverage found" > coverage-by-type/integration-report.txt
          fi

          echo "üìä Processing all test coverage (unit + integration + e2e)..."
          find coverage-artifacts/ -name ".coverage" 2>/dev/null | while read -r file; do
            cp "$file" "coverage-by-type/.coverage.all.$(basename $(dirname $file))"
          done

          if ls coverage-by-type/.coverage.all.* 1> /dev/null 2>&1; then
            cd coverage-by-type
            coverage combine .coverage.all.* --keep
            mv .coverage .coverage.all
            coverage report --data-file=.coverage.all > all-report.txt || echo "No coverage data"
            coverage html --data-file=.coverage.all -d ../coverage-html/ || echo "Could not generate HTML"
            coverage xml --data-file=.coverage.all -o ../coverage-merged.xml || echo "Could not generate XML"
            cat all-report.txt
            cd ..
          else
            echo "No test coverage found" > coverage-by-type/all-report.txt
          fi

      - name: Generate Incremental Coverage Analysis
        run: |
          echo "üî¨ Generating incremental coverage analysis..."
          python scripts/coverage_analysis.py \
            --unit coverage-by-type/unit-report.txt \
            --integration coverage-by-type/integration-report.txt \
            --output coverage-incremental-summary.txt \
            --json-output coverage-data.json


           ## --e2e coverage-by-type/all-report.txt \

      - name: Create Combined Report
        run: |
          DATE=$(date +"%Y-%m-%d %H:%M:%S UTC")
          cat > coverage-full-summary.md << EOF
          # üìä Nightly Test Coverage Report

          **Date:** ${DATE}
          **Run ID:** ${{ github.run_id }}
          **Workflow:** ${{ github.workflow }}

          ---

          $(cat coverage-incremental-summary.txt)

          ---

          ## üìÅ Artifacts
          - Full HTML Report: Download \`coverage-reports-${{ github.run_id }}\` artifact
          - Coverage XML: \`coverage-merged.xml\`
          - Historical Data: \`coverage-data.json\`

          EOF

          echo "üìÑ Coverage report generated"
          cat coverage-full-summary.md

      - name: Post to Workflow Summary
        run: cat coverage-full-summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload Coverage Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-reports-${{ github.run_id }}
          path: |
            coverage-html/
            coverage-merged.xml
            coverage-incremental-summary.txt
            coverage-full-summary.md
            coverage-data.json
          retention-days: 30

      - name: Store Daily Snapshot to Branch
        if: github.event_name == 'schedule'
        run: |
          set -x
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Fetch the coverage branch or create it
          git fetch origin coverage-snapshots:coverage-snapshots || git checkout --orphan coverage-snapshots || true

          # Switch to coverage branch
          git checkout coverage-snapshots 2>/dev/null || git switch --orphan coverage-snapshots

          # Clear working directory but keep our new files
          git rm -rf . 2>/dev/null || true

          # Create snapshot directory
          DATE=$(date +"%Y-%m-%d")
          mkdir -p snapshots/$DATE

          # Copy coverage files to snapshot
          cp coverage-merged.xml snapshots/$DATE/ 2>/dev/null || echo "No XML file"
          cp coverage-incremental-summary.txt snapshots/$DATE/ 2>/dev/null || echo "No summary file"
          cp coverage-data.json snapshots/$DATE/ 2>/dev/null || echo "No JSON file"

          # Create simple index
          cat > snapshots/INDEX.md << 'INDEXEOF'
          # Coverage Snapshots

          This branch contains daily coverage snapshots from nightly builds.

          ## Available Snapshots
          INDEXEOF

          ls -1 snapshots/ | grep -E "^[0-9]{4}-[0-9]{2}-[0-9]{2}$" | sort -r | head -30 | while read date; do
            echo "- [$date](snapshots/$date/)" >> snapshots/INDEX.md
          done

          # Commit and push
          git add snapshots/
          git commit -m "Coverage snapshot: $DATE [run: ${{ github.run_id }}]" || echo "No changes to commit"
          git push origin coverage-snapshots || git push --set-upstream origin coverage-snapshots

  ############################## RESULTS SUMMARY ##############################
  results-summary:
    name: Results Summary
    runs-on: ubuntu-latest
    if: always()
    needs: [unit-tests]
    # needs: [build-amd64, build-arm64, unit-tests, integration-tests, e2e-single-gpu-tests, e2e-multi-gpu-tests, fault-tolerance-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Gather job metadata
        id: gather
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PIPELINE_TYPE: ${{ inputs.pipeline_type }}
        run: |
          set +x -e
          echo "# ${PIPELINE_TYPE^} CI Results Summary" > results.md
          echo "" >> results.md
          echo "| Stage | Status | Runner | Duration (min) | Artifacts |" >> results.md
          echo "|-------|--------|--------|----------------|-----------|" >> results.md

          curl -s -S -L --fail-with-body \
            -H "Authorization: Bearer ${GITHUB_TOKEN}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100" \
            2>/dev/null | jq -c '.jobs[] | {id, name, runner_name, conclusion, started_at, completed_at}' > jobs.jsonl

          while read job_entry; do
            job_id=$(echo "$job_entry" | jq -r '.id')
            name=$(echo "$job_entry" | jq -r '.name')
            runner=$(echo "$job_entry" | jq -r '.runner_name')
            status=$(echo "$job_entry" | jq -r '.conclusion')
            started=$(echo "$job_entry" | jq -r '.started_at')
            completed=$(echo "$job_entry" | jq -r '.completed_at')
            minutes="N/A"
            if [[ "$started" != "null" && "$completed" != "null" ]]; then
              start_epoch=$(date -d "$started" +%s)
              end_epoch=$(date -d "$completed" +%s)
              minutes=$(( (end_epoch - start_epoch)/60 ))
            fi
            artifact_link="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}#job-$job_id"
            printf "| %s | %s | %s | %s | [Log & Artifacts](%s) |\n" "$name" "$status" "$runner" "$minutes" "$artifact_link" >> results.md
          done < jobs.jsonl

          echo "" >> results.md
          echo "---" >> results.md
      - name: Display workflow summary
        run: cat results.md
      - name: Upload results summary as job summary
        run: cat results.md >> $GITHUB_STEP_SUMMARY
      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ inputs.pipeline_type }}-results-summary
          path: results.md
          retention-days: 7

  ############################## SLACK NOTIFICATION ##############################
  notify-slack:
    name: Notify Slack
    runs-on: cpu-amd-m5-4xlarge
    if: always() && inputs.enable_slack_notification && !github.event.repository.fork
    needs: results-summary
    permissions:
      contents: read
    env:
      HAS_SLACK_WEBHOOK: ${{ secrets.SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL != '' }}
    steps:
      - name: Send Slack notification
        if: env.HAS_SLACK_WEBHOOK == 'true'
        continue-on-error: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL }}
          SLACK_OPS_GROUP_ID: ${{ secrets.SLACK_OPS_SUPPORT_GROUP_ID }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          PIPELINE_TYPE: ${{ inputs.pipeline_type }}
        run: |
          set -euo pipefail

          JOBS_JSON=$(mktemp)
          trap 'rm -f "$JOBS_JSON"' EXIT

          if ! curl -sSL \
            -H "Authorization: Bearer ${GITHUB_TOKEN}" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100" \
            > "$JOBS_JSON"; then
            echo "Error: Failed to fetch job data from GitHub API"
            exit 1
          fi

          if [ ! -s "$JOBS_JSON" ]; then
            echo "Error: No job data received"
            exit 1
          fi

          TOTAL_JOBS=$(jq '[.jobs[]] | length' "$JOBS_JSON")
          SUCCESS_COUNT=$(jq '[.jobs[] | select(.conclusion == "success")] | length' "$JOBS_JSON")
          FAILED_COUNT=$(jq '[.jobs[] | select(.conclusion == "failure")] | length' "$JOBS_JSON")

          if [ "$FAILED_COUNT" -eq 0 ]; then
            STATUS="Success ‚úÖ"
            STATUS_EMOJI=":white_check_mark:"
          else
            STATUS="Failed ‚ùå"
            STATUS_EMOJI=":x:"
          fi

          # Capitalize pipeline type for display
          DISPLAY_TYPE="${PIPELINE_TYPE^}"

          # Main message with summary
          SUMMARY_TEXT="*${DISPLAY_TYPE} CI Pipeline - ${STATUS}*"$'\n'"Summary: ${SUCCESS_COUNT}/${TOTAL_JOBS} jobs passed"$'\n'"<${RUN_URL}|View Workflow Summary>"

          if [ "$FAILED_COUNT" -eq 0 ]; then
            # Success - simple message
            PAYLOAD=$(jq -n \
              --arg text "$SUMMARY_TEXT" \
              '{text: $text}')
          else
            # Failed - message with blocks
            FAILED_JOBS=$(jq -r '.jobs[] | select(.conclusion == "failure") | "‚Ä¢ " + .name' "$JOBS_JSON")
            FAILED_JOBS_TEXT="*Failed Jobs (${FAILED_COUNT}):*"$'\n'"${FAILED_JOBS}"

            # Build ops-support mention (use group ID if available, otherwise plain text)
            if [ -n "${SLACK_OPS_GROUP_ID:-}" ]; then
              OPS_MENTION="<!subteam^${SLACK_OPS_GROUP_ID}|@ops-support>"
            else
              OPS_MENTION="@ops-support"
            fi
            ACTION_TEXT=":rotating_light: cc ${OPS_MENTION} - Please investigate the failures above."

            PAYLOAD=$(jq -n \
              --arg summary "$SUMMARY_TEXT" \
              --arg failed "$FAILED_JOBS_TEXT" \
              --arg action "$ACTION_TEXT" \
              '{
                text: $summary,
                blocks: [
                  {
                    type: "section",
                    text: {
                      type: "mrkdwn",
                      text: $summary
                    }
                  },
                  {
                    type: "section",
                    text: {
                      type: "mrkdwn",
                      text: $failed
                    }
                  },
                  {
                    type: "divider"
                  },
                  {
                    type: "context",
                    elements: [
                      {
                        type: "mrkdwn",
                        text: $action
                      }
                    ]
                  }
                ]
              }')
          fi

          if curl -sSf -X POST -H "Content-Type: application/json" -d "$PAYLOAD" "$SLACK_WEBHOOK_URL"; then
            echo "Slack notification sent successfully"
          else
            echo "Warning: Failed to send Slack notification"
            exit 1
          fi

