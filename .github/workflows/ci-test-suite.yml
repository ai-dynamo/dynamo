# SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# Reusable CI Test Suite Workflow
# This workflow is called by nightly-ci.yml and post-merge-ci.yml
# to run the full test suite with configurable parameters.

name: CI Test Suite

on:
  workflow_call:
    inputs:
      pipeline_type:
        description: 'Type of pipeline: nightly or post_merge'
        required: true
        type: string
      include_nightly_marks:
        description: 'Include nightly pytest marks in test selection'
        required: true
        type: boolean
      image_prefix:
        description: 'Prefix for image tags (nightly or main)'
        required: true
        type: string
      enable_slack_notification:
        description: 'Enable Slack notifications on completion'
        required: false
        type: boolean
        default: false
      enable_coverage:
        description: 'Enable test coverage collection and reporting'
        required: false
        type: boolean
        default: false
    secrets:
      AWS_ACCOUNT_ID:
        required: true
      AWS_DEFAULT_REGION:
        required: true
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      NGC_CI_ACCESS_TOKEN:
        required: true
      CI_TOKEN:
        required: true
      SCCACHE_S3_BUCKET:
        required: true
      AZURE_ACR_HOSTNAME:
        required: true
      AZURE_ACR_USER:
        required: true
      AZURE_ACR_PASSWORD:
        required: true
      SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL:
        required: false
      SLACK_OPS_SUPPORT_GROUP_ID:
        required: false
      AZURE_AKS_CI_KUBECONFIG_B64:
        required: false
      HF_TOKEN:
        required: false
      DYNAMO_INGRESS_SUFFIX:
        required: false

permissions:
  contents: read

defaults:
  run:
    shell: bash --noprofile --norc -eo pipefail {0}

env:
  REGISTRY_IMAGE: ai-dynamo/dynamo
  IMAGE_PREFIX: ${{ inputs.image_prefix }}

############################## BUILD JOBS ##############################

############################## TEST JOBS ##############################

  unit-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-unit
    # needs: [build-amd64, build-arm64]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: gpu-l40-amd64
          - arch: arm64
            runner: cpu-arm-r8g-4xlarge
    steps:
      - uses: actions/checkout@v4
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        shell: bash
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run Unit Tests
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
          pytest_marks: ${{ inputs.include_nightly_marks && 'unit and (nightly or post_merge or pre_merge)' || 'unit and (post_merge or pre_merge)' }}
          framework: ${{ matrix.framework }}
          test_type: unit
          platform_arch: ${{ matrix.arch.arch }}
          cpu_limit: '8'
          dry_run: ${{ matrix.arch.arch == 'arm64' && 'true' || 'false' }}
          enable_coverage: ${{ inputs.enable_coverage }}

  integration-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-integ
    # needs: [build-amd64, build-arm64]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: ${{ matrix.arch.timeout }}
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: gpu-l40-amd64
            timeout: 90
          - arch: arm64
            runner: cpu-arm-r8g-4xlarge
            timeout: 90
    steps:
      - uses: actions/checkout@v4
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        shell: bash
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run Integration Tests
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ env.IMAGE_PREFIX }}-${{ matrix.framework }}-${{ matrix.arch.arch }}
          pytest_marks: ${{ inputs.include_nightly_marks && 'integration and (nightly or post_merge or pre_merge)' || 'integration and (post_merge or pre_merge)' }}
          framework: ${{ matrix.framework }}
          test_type: integration
          platform_arch: ${{ matrix.arch.arch }}
          dry_run: ${{ matrix.arch.arch == 'arm64' && 'true' || 'false' }}
          enable_coverage: ${{ inputs.enable_coverage }}

  ############################## FAULT TOLERANCE TESTS ##############################

  ############################## COVERAGE REPORT ##############################
  coverage-report:
    name: Generate Coverage Report
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: inputs.enable_coverage && always()
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Coverage Tools
        run: |
          pip install coverage[toml]==7.4.0 pytest-cov
          echo "‚úÖ Coverage tools installed"

      - name: Download All Coverage Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-python-*
          path: coverage-artifacts/
          merge-multiple: false

      - name: List Downloaded Artifacts
        run: |
          echo "üì¶ Downloaded coverage artifacts:"
          echo "==== Directory structure ===="
          ls -R coverage-artifacts/
          echo ""
          echo "==== Coverage files found ===="
          find coverage-artifacts/ -type f \( -name "*.xml" -o -name ".coverage*" \) | sort
          echo ""
          echo "==== Specifically looking for .coverage files ===="
          find coverage-artifacts/ -name ".coverage" -type f

      - name: Merge All Coverage Data
        run: |
          set -x
          echo "üìä Merging all test coverage..."

          # Find all .coverage files and copy them with unique names
          mkdir -p coverage-combined
          find coverage-artifacts/ -name ".coverage" 2>/dev/null | while read -r file; do
            unique_name=$(echo "$file" | tr '/' '_' | sed 's/coverage-artifacts_//')
            cp "$file" "coverage-combined/.coverage.${unique_name}"
          done

          # Check if we have any coverage files
          if ls coverage-combined/.coverage.* 1> /dev/null 2>&1; then
            echo "‚úÖ Found coverage files to merge"
            cd coverage-combined

            # Combine all coverage data
            coverage combine .coverage.* --keep
            mv .coverage ../
            cd ..

            # Generate reports
            echo "üìä Generating coverage reports..."
            coverage report --data-file=.coverage | tee coverage-report.txt
            coverage html --data-file=.coverage -d coverage-html/
            coverage xml --data-file=.coverage -o coverage-merged.xml

            # Extract total coverage percentage
            TOTAL_COVERAGE=$(grep "TOTAL" coverage-report.txt | awk '{print $NF}')
            echo "üìà Total Coverage: ${TOTAL_COVERAGE}"
            echo "TOTAL_COVERAGE=${TOTAL_COVERAGE}" >> $GITHUB_ENV
          else
            echo "‚ö†Ô∏è  No coverage data found"
            echo "No coverage data available" > coverage-report.txt
            echo "TOTAL_COVERAGE=0%" >> $GITHUB_ENV
          fi


      - name: Create Coverage Summary
        run: |
          DATE=$(date +"%Y-%m-%d %H:%M:%S UTC")
          cat > coverage-summary.md << EOF
          # üìä Test Coverage Report

          **Date:** ${DATE}
          **Run ID:** ${{ github.run_id }}
          **Workflow:** ${{ github.workflow }}
          **Total Coverage:** ${TOTAL_COVERAGE}

          ---

          ## Coverage Details

          \`\`\`
          $(cat coverage-report.txt 2>/dev/null || echo "No coverage data available")
          \`\`\`

          ---

          ## üìÅ Artifacts
          - Full HTML Report: Download \`coverage-reports-${{ github.run_id }}\` artifact
          - Coverage XML: \`coverage-merged.xml\`

          EOF

          echo "üìÑ Coverage summary generated"
          cat coverage-summary.md

      - name: Post to Workflow Summary
        run: cat coverage-summary.md >> $GITHUB_STEP_SUMMARY

      - name: Upload Coverage Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-reports-${{ github.run_id }}
          path: |
            coverage-html/
            coverage-merged.xml
            coverage-report.txt
            coverage-summary.md
            .coverage
          retention-days: 30

      - name: Store Daily Snapshot to Branch
        if: github.event_name == 'schedule'
        run: |
          set -x
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Fetch the coverage branch or create it
          git fetch origin coverage-snapshots:coverage-snapshots || git checkout --orphan coverage-snapshots || true

          # Switch to coverage branch
          git checkout coverage-snapshots 2>/dev/null || git switch --orphan coverage-snapshots

          # Clear working directory but keep our new files
          git rm -rf . 2>/dev/null || true

          # Create snapshot directory
          DATE=$(date +"%Y-%m-%d")
          mkdir -p snapshots/$DATE

          # Copy coverage files to snapshot
          cp coverage-merged.xml snapshots/$DATE/ 2>/dev/null || echo "No XML file"
          cp coverage-report.txt snapshots/$DATE/ 2>/dev/null || echo "No report file"
          cp coverage-summary.md snapshots/$DATE/ 2>/dev/null || echo "No summary file"

          # Create simple index
          cat > snapshots/INDEX.md << 'INDEXEOF'
          # Coverage Snapshots

          This branch contains daily coverage snapshots from nightly builds.

          ## Available Snapshots
          INDEXEOF

          ls -1 snapshots/ | grep -E "^[0-9]{4}-[0-9]{2}-[0-9]{2}$" | sort -r | head -30 | while read date; do
            echo "- [$date](snapshots/$date/)" >> snapshots/INDEX.md
          done

          # Commit and push
          git add snapshots/
          git commit -m "Coverage snapshot: $DATE [run: ${{ github.run_id }}]" || echo "No changes to commit"
          git push origin coverage-snapshots || git push --set-upstream origin coverage-snapshots

  ############################## RESULTS SUMMARY ##############################
  results-summary:
    name: Results Summary
    runs-on: ubuntu-latest
    if: always()
    needs: [unit-tests]
    # needs: [build-amd64, build-arm64, unit-tests, integration-tests, e2e-single-gpu-tests, e2e-multi-gpu-tests, fault-tolerance-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Gather job metadata
        id: gather
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PIPELINE_TYPE: ${{ inputs.pipeline_type }}
        run: |
          set +x -e
          echo "# ${PIPELINE_TYPE^} CI Results Summary" > results.md
          echo "" >> results.md
          echo "| Stage | Status | Runner | Duration (min) | Artifacts |" >> results.md
          echo "|-------|--------|--------|----------------|-----------|" >> results.md

          curl -s -S -L --fail-with-body \
            -H "Authorization: Bearer ${GITHUB_TOKEN}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100" \
            2>/dev/null | jq -c '.jobs[] | {id, name, runner_name, conclusion, started_at, completed_at}' > jobs.jsonl

          while read job_entry; do
            job_id=$(echo "$job_entry" | jq -r '.id')
            name=$(echo "$job_entry" | jq -r '.name')
            runner=$(echo "$job_entry" | jq -r '.runner_name')
            status=$(echo "$job_entry" | jq -r '.conclusion')
            started=$(echo "$job_entry" | jq -r '.started_at')
            completed=$(echo "$job_entry" | jq -r '.completed_at')
            minutes="N/A"
            if [[ "$started" != "null" && "$completed" != "null" ]]; then
              start_epoch=$(date -d "$started" +%s)
              end_epoch=$(date -d "$completed" +%s)
              minutes=$(( (end_epoch - start_epoch)/60 ))
            fi
            artifact_link="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}#job-$job_id"
            printf "| %s | %s | %s | %s | [Log & Artifacts](%s) |\n" "$name" "$status" "$runner" "$minutes" "$artifact_link" >> results.md
          done < jobs.jsonl

          echo "" >> results.md
          echo "---" >> results.md
      - name: Display workflow summary
        run: cat results.md
      - name: Upload results summary as job summary
        run: cat results.md >> $GITHUB_STEP_SUMMARY
      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ inputs.pipeline_type }}-results-summary
          path: results.md
          retention-days: 7

  ############################## SLACK NOTIFICATION ##############################
  notify-slack:
    name: Notify Slack
    runs-on: cpu-amd-m5-4xlarge
    if: always() && inputs.enable_slack_notification && !github.event.repository.fork
    needs: results-summary
    permissions:
      contents: read
    env:
      HAS_SLACK_WEBHOOK: ${{ secrets.SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL != '' }}
    steps:
      - name: Send Slack notification
        if: env.HAS_SLACK_WEBHOOK == 'true'
        continue-on-error: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL }}
          SLACK_OPS_GROUP_ID: ${{ secrets.SLACK_OPS_SUPPORT_GROUP_ID }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          PIPELINE_TYPE: ${{ inputs.pipeline_type }}
        run: |
          set -euo pipefail

          JOBS_JSON=$(mktemp)
          trap 'rm -f "$JOBS_JSON"' EXIT

          if ! curl -sSL \
            -H "Authorization: Bearer ${GITHUB_TOKEN}" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100" \
            > "$JOBS_JSON"; then
            echo "Error: Failed to fetch job data from GitHub API"
            exit 1
          fi

          if [ ! -s "$JOBS_JSON" ]; then
            echo "Error: No job data received"
            exit 1
          fi

          TOTAL_JOBS=$(jq '[.jobs[]] | length' "$JOBS_JSON")
          SUCCESS_COUNT=$(jq '[.jobs[] | select(.conclusion == "success")] | length' "$JOBS_JSON")
          FAILED_COUNT=$(jq '[.jobs[] | select(.conclusion == "failure")] | length' "$JOBS_JSON")

          if [ "$FAILED_COUNT" -eq 0 ]; then
            STATUS="Success ‚úÖ"
            STATUS_EMOJI=":white_check_mark:"
          else
            STATUS="Failed ‚ùå"
            STATUS_EMOJI=":x:"
          fi

          # Capitalize pipeline type for display
          DISPLAY_TYPE="${PIPELINE_TYPE^}"

          # Main message with summary
          SUMMARY_TEXT="*${DISPLAY_TYPE} CI Pipeline - ${STATUS}*"$'\n'"Summary: ${SUCCESS_COUNT}/${TOTAL_JOBS} jobs passed"$'\n'"<${RUN_URL}|View Workflow Summary>"

          if [ "$FAILED_COUNT" -eq 0 ]; then
            # Success - simple message
            PAYLOAD=$(jq -n \
              --arg text "$SUMMARY_TEXT" \
              '{text: $text}')
          else
            # Failed - message with blocks
            FAILED_JOBS=$(jq -r '.jobs[] | select(.conclusion == "failure") | "‚Ä¢ " + .name' "$JOBS_JSON")
            FAILED_JOBS_TEXT="*Failed Jobs (${FAILED_COUNT}):*"$'\n'"${FAILED_JOBS}"

            # Build ops-support mention (use group ID if available, otherwise plain text)
            if [ -n "${SLACK_OPS_GROUP_ID:-}" ]; then
              OPS_MENTION="<!subteam^${SLACK_OPS_GROUP_ID}|@ops-support>"
            else
              OPS_MENTION="@ops-support"
            fi
            ACTION_TEXT=":rotating_light: cc ${OPS_MENTION} - Please investigate the failures above."

            PAYLOAD=$(jq -n \
              --arg summary "$SUMMARY_TEXT" \
              --arg failed "$FAILED_JOBS_TEXT" \
              --arg action "$ACTION_TEXT" \
              '{
                text: $summary,
                blocks: [
                  {
                    type: "section",
                    text: {
                      type: "mrkdwn",
                      text: $summary
                    }
                  },
                  {
                    type: "section",
                    text: {
                      type: "mrkdwn",
                      text: $failed
                    }
                  },
                  {
                    type: "divider"
                  },
                  {
                    type: "context",
                    elements: [
                      {
                        type: "mrkdwn",
                        text: $action
                      }
                    ]
                  }
                ]
              }')
          fi

          if curl -sSf -X POST -H "Content-Type: application/json" -d "$PAYLOAD" "$SLACK_WEBHOOK_URL"; then
            echo "Slack notification sent successfully"
          else
            echo "Warning: Failed to send Slack notification"
            exit 1
          fi

