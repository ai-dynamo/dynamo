# SPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# Reusable CI Test Suite Workflow
# Called by release.yml, nightly-ci.yml, and post-merge-ci.yml.
# Uses the same build-test-distribute-flavor-matrix.yml engine as pr.yaml
# to eliminate build duplication. Optional features (operator, frontend,
# deploy-tests) are gated by inputs.

name: CI Test Suite

on:
  workflow_call:
    inputs:
      pipeline_type:
        description: 'Type of pipeline: nightly, post_merge, or release'
        required: true
        type: string
      include_nightly_marks:
        description: 'Include nightly pytest marks in test selection'
        required: true
        type: boolean
      image_prefix:
        description: 'Prefix for image tags (e.g., nightly, main, release-0.9.0)'
        required: true
        type: string
      enable_slack_notification:
        description: 'Enable Slack notifications on completion'
        required: false
        type: boolean
        default: false
      build_operator:
        description: 'Build the operator image'
        required: false
        type: boolean
        default: false
      build_frontend:
        description: 'Build frontend images'
        required: false
        type: boolean
        default: false
      run_deploy_tests:
        description: 'Run Kubernetes deployment tests'
        required: false
        type: boolean
        default: false
    secrets:
      AWS_ACCOUNT_ID:
        required: true
      AWS_DEFAULT_REGION:
        required: true
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      NGC_CI_ACCESS_TOKEN:
        required: true
      CI_TOKEN:
        required: true
      SCCACHE_S3_BUCKET:
        required: true
      AZURE_ACR_HOSTNAME:
        required: true
      AZURE_ACR_USER:
        required: true
      AZURE_ACR_PASSWORD:
        required: true
      SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL:
        required: false
      SLACK_OPS_SUPPORT_GROUP_ID:
        required: false
      AZURE_AKS_CI_KUBECONFIG_B64:
        required: false
      HF_TOKEN:
        required: false
      DYNAMO_INGRESS_SUFFIX:
        required: false

permissions:
  contents: read

defaults:
  run:
    shell: bash --noprofile --norc -eo pipefail {0}

env:
  REGISTRY_IMAGE: ai-dynamo/dynamo
  IMAGE_PREFIX: ${{ inputs.image_prefix }}
  BUILDER_NAME: b-${{ github.run_id }}-${{ github.run_attempt }}

############################## BUILD JOBS ##############################
# Uses the same flavor-matrix engine as pr.yaml. Each framework is a
# separate parent job so test jobs can check per-framework build status
# via the needs context (no GitHub API polling needed).

jobs:
  vllm-pipeline:
    name: vllm builds
    uses: ./.github/workflows/build-test-distribute-flavor-matrix.yml
    with:
      framework: vllm
      target: runtime
      platforms: '["amd64", "arm64"]'
      cuda_versions: '["12.9", "13.0"]'
      run_tests: false
      extra_tags: |
        ${{ inputs.image_prefix }}-vllm
      builder_name: b-${{ github.run_id }}-${{ github.run_attempt }}
      build_timeout_minutes: 120
    secrets: inherit

  sglang-pipeline:
    name: sglang builds
    uses: ./.github/workflows/build-test-distribute-flavor-matrix.yml
    with:
      framework: sglang
      target: runtime
      platforms: '["amd64", "arm64"]'
      cuda_versions: '["12.9", "13.0"]'
      run_tests: false
      extra_tags: |
        ${{ inputs.image_prefix }}-sglang
      builder_name: b-${{ github.run_id }}-${{ github.run_attempt }}
      build_timeout_minutes: 120
    secrets: inherit

  trtllm-pipeline:
    name: trtllm builds
    uses: ./.github/workflows/build-test-distribute-flavor-matrix.yml
    with:
      framework: trtllm
      target: runtime
      platforms: '["amd64", "arm64"]'
      cuda_versions: '["13.1"]'
      run_tests: false
      extra_tags: |
        ${{ inputs.image_prefix }}-trtllm
      builder_name: b-${{ github.run_id }}-${{ github.run_attempt }}
      build_timeout_minutes: 120
    secrets: inherit

  # ---- Optional: Operator build (for release and deploy tests) ----
  operator-build:
    name: Build Operator Image
    if: inputs.build_operator
    runs-on: prod-default-v2
    env:
      IMAGE_REGISTRY: ai-dynamo
      IMAGE_REPOSITORY: dynamo
      ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
    outputs:
      operator_tag: ${{ steps.build-and-push.outputs.operator_tag }}
    steps:
      - uses: actions/checkout@v4
      - name: Initialize Dynamo Builder
        uses: ./.github/actions/init-dynamo-builder
        with:
          builder_name: ${{ env.BUILDER_NAME }}
          flavor: general
          all_arch: 'true'
      - name: Docker Login
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}
      - name: Linter
        working-directory: ./deploy/operator
        run: docker buildx build --platform linux/arm64 --target linter --progress=plain --build-arg DOCKER_PROXY=${ECR_HOSTNAME}/dockerhub/ .
      - name: Tester
        working-directory: ./deploy/operator
        run: docker buildx build --platform linux/arm64 --target tester --progress=plain --build-arg DOCKER_PROXY=${ECR_HOSTNAME}/dockerhub/ .
      - name: Build and push Container
        id: build-and-push
        working-directory: ./deploy/operator
        run: |
          ECR_BASE="${ECR_HOSTNAME}/${IMAGE_REGISTRY}/${IMAGE_REPOSITORY}"
          ACR_BASE="${{ secrets.AZURE_ACR_HOSTNAME }}/${IMAGE_REGISTRY}/${IMAGE_REPOSITORY}"
          SHA_TAG="${{ github.sha }}-operator"
          PREFIX_TAG="${{ inputs.image_prefix }}-operator"
          IMAGE_URIS=(
            "${ECR_BASE}:${SHA_TAG}"
            "${ECR_BASE}:${PREFIX_TAG}"
            "${ACR_BASE}:${SHA_TAG}"
            "${ACR_BASE}:${PREFIX_TAG}"
          )
          echo "operator_tag=${PREFIX_TAG}" >> $GITHUB_OUTPUT
          TAGGING_FLAGS=$(printf -- '-t %s ' "${IMAGE_URIS[@]}")
          docker buildx build --push --platform linux/amd64,linux/arm64 \
              --build-arg DOCKER_PROXY=${ECR_HOSTNAME}/dockerhub/ \
              ${TAGGING_FLAGS} -f Dockerfile .

  # ---- Optional: Frontend build (for release) ----
  frontend-build:
    name: Build Frontend Images
    if: inputs.build_frontend
    uses: ./.github/workflows/build-frontend-image.yaml
    with:
      skip_change_detection: true
      image_prefix: ${{ inputs.image_prefix }}
    secrets: inherit

  # ---- Builder cleanup ----
  clean-k8s-builder:
    name: Clean K8s builder if exists
    runs-on: prod-default-small-v2
    if: always()
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline]
    steps:
    - uses: actions/checkout@v4
    - name: Create K8s builders (skip bootstrap)
      uses: ./.github/actions/bootstrap-buildkit
      continue-on-error: true
      with:
        builder_name: b-${{ github.run_id }}-${{ github.run_attempt }}
        buildkit_worker_addresses: ''
        skip_bootstrap: true
    - name: Builder Cleanup
      run: docker buildx rm b-${{ github.run_id }}-${{ github.run_attempt }} || true

############################## TEST JOBS ##############################
# Tests depend on per-framework pipeline jobs. The needs context is used
# to check per-framework build status instead of the old GitHub API script.

  unit-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-unit
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: prod-builder-amd-gpu-v1
          - arch: arm64
            runner: prod-builder-arm-v1
    steps:
      - uses: actions/checkout@v4
      - name: Check if build succeeded
        id: check_build
        run: |
          case "${{ matrix.framework }}" in
            vllm)   RESULT="${{ needs.vllm-pipeline.result }}" ;;
            sglang) RESULT="${{ needs.sglang-pipeline.result }}" ;;
            trtllm) RESULT="${{ needs.trtllm-pipeline.result }}" ;;
          esac
          echo "Build result for ${{ matrix.framework }}: $RESULT"
          if [ "$RESULT" != "success" ]; then
            echo "Build for ${{ matrix.framework }} did not succeed, skipping tests"
            exit 1
          fi
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run Unit Tests
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
          pytest_marks: ${{ inputs.include_nightly_marks && 'unit and (nightly or post_merge or pre_merge)' || 'unit and (post_merge or pre_merge)' }}
          framework: ${{ matrix.framework }}
          test_type: unit
          platform_arch: ${{ matrix.arch.arch }}
          cpu_limit: '8'
          dry_run: ${{ matrix.arch.arch == 'arm64' && 'true' || 'false' }}

  integration-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-integ
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: ${{ matrix.arch.timeout }}
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: prod-builder-amd-gpu-v1
            timeout: 90
          - arch: arm64
            runner: prod-builder-arm-v1
            timeout: 90
    steps:
      - uses: actions/checkout@v4
      - name: Check if build succeeded
        run: |
          case "${{ matrix.framework }}" in
            vllm)   RESULT="${{ needs.vllm-pipeline.result }}" ;;
            sglang) RESULT="${{ needs.sglang-pipeline.result }}" ;;
            trtllm) RESULT="${{ needs.trtllm-pipeline.result }}" ;;
          esac
          echo "Build result for ${{ matrix.framework }}: $RESULT"
          if [ "$RESULT" != "success" ]; then
            echo "Build for ${{ matrix.framework }} did not succeed, skipping tests"
            exit 1
          fi
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run Integration Tests
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
          pytest_marks: ${{ inputs.include_nightly_marks && 'integration and (nightly or post_merge or pre_merge)' || 'integration and (post_merge or pre_merge)' }}
          framework: ${{ matrix.framework }}
          test_type: integration
          platform_arch: ${{ matrix.arch.arch }}
          dry_run: ${{ matrix.arch.arch == 'arm64' && 'true' || 'false' }}

  e2e-single-gpu-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-1gpu-e2e
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: ${{ matrix.arch.timeout }}
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: prod-builder-amd-gpu-v1
            timeout: 180
          - arch: arm64
            runner: prod-builder-arm-v1
            timeout: 180
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
      - name: Check if build succeeded
        run: |
          case "${{ matrix.framework }}" in
            vllm)   RESULT="${{ needs.vllm-pipeline.result }}" ;;
            sglang) RESULT="${{ needs.sglang-pipeline.result }}" ;;
            trtllm) RESULT="${{ needs.trtllm-pipeline.result }}" ;;
          esac
          echo "Build result for ${{ matrix.framework }}: $RESULT"
          if [ "$RESULT" != "success" ]; then
            echo "Build for ${{ matrix.framework }} did not succeed, skipping tests"
            exit 1
          fi
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run E2E Tests (gpu_1)
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
          pytest_marks: "${{ matrix.framework }} and e2e and gpu_1"
          framework: ${{ matrix.framework }}
          test_type: e2e-single-gpu
          platform_arch: ${{ matrix.arch.arch }}
          dry_run: ${{ matrix.arch.arch == 'arm64' && 'true' || 'false' }}

  e2e-multi-gpu-tests:
    name: ${{ matrix.framework }}-${{ matrix.arch.arch }}-2gpu-e2e
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline]
    if: always()
    runs-on: ${{ matrix.arch.runner }}
    timeout-minutes: ${{ matrix.arch.timeout }}
    strategy:
      fail-fast: false
      matrix:
        framework: [vllm, trtllm, sglang]
        arch:
          - arch: amd64
            runner: prod-builder-amd-gpu-v1
            timeout: 150
          - arch: arm64
            runner: prod-builder-arm-v1
            timeout: 150
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
      - name: Check if build succeeded
        run: |
          case "${{ matrix.framework }}" in
            vllm)   RESULT="${{ needs.vllm-pipeline.result }}" ;;
            sglang) RESULT="${{ needs.sglang-pipeline.result }}" ;;
            trtllm) RESULT="${{ needs.trtllm-pipeline.result }}" ;;
          esac
          echo "Build result for ${{ matrix.framework }}: $RESULT"
          if [ "$RESULT" != "success" ]; then
            echo "Build for ${{ matrix.framework }} did not succeed, skipping tests"
            exit 1
          fi
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      - name: Pull image
        env:
          ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
          IMAGE_TAG: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
        run: |
          docker pull ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG}
          docker tag ${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${IMAGE_TAG} ${IMAGE_TAG}
      - name: Run E2E Tests (gpu_2)
        uses: ./.github/actions/pytest
        with:
          image_tag: ${{ inputs.image_prefix }}-${{ matrix.framework }}-${{ matrix.framework == 'trtllm' && 'cuda13' || 'cuda12' }}-${{ matrix.arch.arch }}
          pytest_marks: ${{ inputs.include_nightly_marks && '(nightly or post_merge or pre_merge) and e2e and gpu_2' || '(post_merge or pre_merge) and e2e and gpu_2' }}
          framework: ${{ matrix.framework }}
          test_type: e2e-multi-gpu
          platform_arch: ${{ matrix.arch.arch }}
          dry_run: 'true'

  ############################## FAULT TOLERANCE TESTS ##############################
  fault-tolerance-tests:
    name: ${{ matrix.framework.name }}-ft-k8s
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline]
    if: always() && inputs.pipeline_type == 'nightly'
    runs-on: prod-builder-amd-v1
    timeout-minutes: 60
    strategy:
      fail-fast: false
      matrix:
        framework:
          - name: vllm
            test_scenario: "vllm-agg"
            cuda_suffix: cuda12
          - name: trtllm
            test_scenario: "trtllm-agg"
            cuda_suffix: cuda13
          - name: sglang
            test_scenario: "sglang-agg"
            cuda_suffix: cuda12
    env:
      ECR_HOSTNAME: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_DEFAULT_REGION }}.amazonaws.com
      NAMESPACE: ft-${{ matrix.framework.name }}-${{ github.run_id }}-${{ github.run_attempt }}
      DYNAMO_INGRESS_SUFFIX: ${{ secrets.DYNAMO_INGRESS_SUFFIX }}
    steps:
      - uses: actions/checkout@v4
      - name: Check if build succeeded
        run: |
          case "${{ matrix.framework.name }}" in
            vllm)   RESULT="${{ needs.vllm-pipeline.result }}" ;;
            sglang) RESULT="${{ needs.sglang-pipeline.result }}" ;;
            trtllm) RESULT="${{ needs.trtllm-pipeline.result }}" ;;
          esac
          if [ "$RESULT" != "success" ]; then
            echo "Build for ${{ matrix.framework.name }} did not succeed, skipping"
            exit 1
          fi
      - name: Login to Container Registries
        uses: ./.github/actions/docker-login
        with:
          aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}
      - name: Setup Kubernetes
        run: |
          echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
          chmod 600 .kubeconfig
          export KUBECONFIG=$(pwd)/.kubeconfig
          kubectl cluster-info
      - name: Deploy Operator
        run: |
          set -x
          export KUBECONFIG=$(pwd)/.kubeconfig
          kubectl delete namespace $NAMESPACE || true
          kubectl create namespace $NAMESPACE || true
          kubectl label namespaces ${NAMESPACE} nscleanup/enabled=true nscleanup/ttl=7200 gitlab-imagepull=enabled ngc-api=enabled nvcr-imagepull=enabled --overwrite=true
          kubectl config set-context --current --namespace=$NAMESPACE
          kubectl get pods -n istio-system
          kubectl get storageclass
          kubectl create secret generic hf-token-secret --from-literal=HF_TOKEN=${{ secrets.HF_TOKEN }} -n $NAMESPACE || true
          kubectl create secret docker-registry docker-imagepullsecret --docker-server=${{ secrets.AZURE_ACR_HOSTNAME }} --docker-username=${{ secrets.AZURE_ACR_USER }} --docker-password=${{ secrets.AZURE_ACR_PASSWORD }} --namespace=${NAMESPACE}
          helm repo add bitnami https://charts.bitnami.com/bitnami
          cd deploy/helm/charts/platform/
          helm dep build .
          helm upgrade --install dynamo-platform . --namespace ${NAMESPACE} \
            --set dynamo-operator.namespaceRestriction.enabled=true \
            --set dynamo-operator.namespaceRestriction.allowedNamespaces[0]=${NAMESPACE} \
            --set dynamo-operator.controllerManager.manager.image.repository=${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo \
            --set dynamo-operator.controllerManager.manager.image.tag=${{ github.sha }}-operator \
            --set dynamo-operator.imagePullSecrets[0].name=docker-imagepullsecret \
            --timeout 10m --wait
          timeout 300s kubectl rollout status deployment -n $NAMESPACE --watch
          cd -
      - name: Run Fault Tolerance Tests
        id: run-ft-tests
        run: |
          set -x
          export KUBECONFIG=$(pwd)/.kubeconfig
          export NAMESPACE=$NAMESPACE
          export FRAMEWORK=${{ matrix.framework.name }}
          export IMAGE="${ECR_HOSTNAME}/${{ env.REGISTRY_IMAGE }}:${{ inputs.image_prefix }}-${FRAMEWORK}-${{ matrix.framework.cuda_suffix }}-amd64"
          echo "Running fault tolerance test: ${{ matrix.framework.test_scenario }}"
          echo "Using image: ${IMAGE}"
          sudo apt-get update && sudo apt-get install -y python3-venv
          python3 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install -r container/deps/requirements.test.txt
          pip install kubernetes==32.0.1 kubernetes_asyncio kr8s pyyaml requests tabulate pydantic
          mkdir -p test-results
          set +e
          pytest tests/fault_tolerance/deploy/test_deployment.py \
            -m 'k8s and fault_tolerance' \
            -k '${{ matrix.framework.test_scenario }}' \
            -s -v \
            --namespace ${NAMESPACE} \
            --image ${IMAGE} \
            --client-type legacy \
            --junitxml=test-results/pytest_ft_report.xml \
            --tb=short
          TEST_EXIT_CODE=$?
          echo "TEST_EXIT_CODE=${TEST_EXIT_CODE}" >> $GITHUB_ENV
          exit ${TEST_EXIT_CODE}
        continue-on-error: true
      - name: Process Fault Tolerance Test Results
        if: always()
        run: |
          if [ -f "test-results/pytest_ft_report.xml" ]; then
            mv "test-results/pytest_ft_report.xml" "test-results/pytest_ft_report_${{ matrix.framework.name }}_amd64_${{ github.run_id }}_${{ job.check_run_id }}.xml"
          fi
      - name: Upload Fault Tolerance Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.framework.name }}-fault_tolerance-amd64-${{ github.run_id }}-${{ job.check_run_id }}
          path: test-results/pytest_ft_report_${{ matrix.framework.name }}_amd64_${{ github.run_id }}_${{ job.check_run_id }}.xml
          retention-days: 7
      - name: Cleanup
        if: always()
        timeout-minutes: 5
        run: |
          echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
          chmod 600 .kubeconfig
          export KUBECONFIG=$(pwd)/.kubeconfig
          kubectl config set-context --current --namespace=$NAMESPACE --kubeconfig "${KUBECONFIG}"
          kubectl get all || true
          kubectl delete dynamographdeployments --all -n $NAMESPACE || true
          helm uninstall dynamo-platform || true
          kubectl delete namespace $NAMESPACE || true

  ############################## OPTIONAL: DEPLOYMENT TESTS ##############################
  deploy-operator:
    name: Deploy Operator
    runs-on: prod-default-small-v2
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline, operator-build]
    if: |
      always() &&
      inputs.run_deploy_tests &&
      needs.operator-build.result == 'success'
    outputs:
      NAMESPACE: ${{ steps.deploy.outputs.namespace }}
    steps:
    - uses: actions/checkout@v4
    - name: Deploy Operator
      id: deploy
      run: |
        set -x
        BRANCH="${{ github.ref_name }}"
        BRANCH_SANITIZED="${BRANCH//\//-}"
        BRANCH_SANITIZED="${BRANCH_SANITIZED//./-}"
        BRANCH_SANITIZED="${BRANCH_SANITIZED:0:10}"
        NAMESPACE="gh-ci-${{ github.run_id }}-${BRANCH_SANITIZED}-dt"
        echo "namespace=${NAMESPACE}" >> "$GITHUB_OUTPUT"

        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
        chmod 600 .kubeconfig
        export KUBECONFIG=$(pwd)/.kubeconfig
        kubectl config set-context --current --namespace=$NAMESPACE

        kubectl create namespace $NAMESPACE
        kubectl label namespaces ${NAMESPACE} nscleanup/enabled=true nscleanup/ttl=7200 gitlab-imagepull=enabled ngc-api=enabled nvcr-imagepull=enabled --overwrite=true
        kubectl config set-context --current --namespace=$NAMESPACE
        kubectl create secret generic hf-token-secret --from-literal=HF_TOKEN=${{ secrets.HF_TOKEN }} -n $NAMESPACE || true

        helm repo add bitnami https://charts.bitnami.com/bitnami
        cd deploy/helm/charts/platform/
        helm dep build .
        helm upgrade --install dynamo-platform . --namespace ${NAMESPACE} \
          --set dynamo-operator.namespaceRestriction.enabled=true \
          --set dynamo-operator.namespaceRestriction.allowedNamespaces[0]=${NAMESPACE} \
          --set dynamo-operator.controllerManager.manager.image.repository=${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo \
          --set dynamo-operator.controllerManager.manager.image.tag=${{ inputs.image_prefix }}-operator \
          --set dynamo-operator.gpuDiscovery.enabled=false \
          --set dynamo-operator.upgradeCRD=false \
          --debug
        timeout 300s kubectl rollout status deployment -n $NAMESPACE --watch

  deploy-test-vllm:
    if: always() && inputs.run_deploy_tests && needs.deploy-operator.result == 'success'
    runs-on: prod-default-small-v2
    needs: [deploy-operator, vllm-pipeline]
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        profile: [agg, agg_router, disagg, disagg_router]
    name: deploy-test-vllm (${{ matrix.profile }})
    steps:
      - uses: actions/checkout@v4
      - name: Run Dynamo Deploy Test
        uses: ./.github/actions/dynamo-deploy-test
        with:
          kubeconfig_base64: ${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}
          namespace: ${{ needs.deploy-operator.outputs.NAMESPACE }}
          framework: vllm
          profile: ${{ matrix.profile }}
          image: ${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:${{ github.sha }}-vllm-cuda12-amd64
          platform_arch: amd64

  deploy-test-sglang:
    if: always() && inputs.run_deploy_tests && needs.deploy-operator.result == 'success'
    runs-on: prod-default-small-v2
    needs: [deploy-operator, sglang-pipeline]
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        profile: [agg, agg_router]
    name: deploy-test-sglang (${{ matrix.profile }})
    steps:
      - uses: actions/checkout@v4
      - name: Run Dynamo Deploy Test
        uses: ./.github/actions/dynamo-deploy-test
        with:
          kubeconfig_base64: ${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}
          namespace: ${{ needs.deploy-operator.outputs.NAMESPACE }}
          framework: sglang
          profile: ${{ matrix.profile }}
          image: ${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:${{ github.sha }}-sglang-cuda12-amd64
          platform_arch: amd64

  deploy-test-trtllm:
    if: always() && inputs.run_deploy_tests && needs.deploy-operator.result == 'success'
    runs-on: prod-default-small-v2
    needs: [deploy-operator, trtllm-pipeline]
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        profile: [agg, agg_router, disagg, disagg_router]
    name: deploy-test-trtllm (${{ matrix.profile }})
    steps:
      - uses: actions/checkout@v4
      - name: Run Dynamo Deploy Test
        uses: ./.github/actions/dynamo-deploy-test
        with:
          kubeconfig_base64: ${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}
          namespace: ${{ needs.deploy-operator.outputs.NAMESPACE }}
          framework: trtllm
          profile: ${{ matrix.profile }}
          image: ${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:${{ github.sha }}-trtllm-cuda13-amd64
          platform_arch: amd64

  deploy-cleanup:
    name: Cleanup AKS resources
    runs-on: prod-default-small-v2
    if: always() && inputs.run_deploy_tests
    needs: [deploy-operator, deploy-test-sglang, deploy-test-trtllm, deploy-test-vllm]
    steps:
    - uses: actions/checkout@v4
    - name: Cleanup
      timeout-minutes: 5
      env:
        NAMESPACE: ${{ needs.deploy-operator.outputs.NAMESPACE }}
      run: |
        if [ -z "$NAMESPACE" ]; then
          echo "No namespace to clean up"
          exit 0
        fi
        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > .kubeconfig
        chmod 600 .kubeconfig
        export KUBECONFIG=$(pwd)/.kubeconfig
        kubectl config set-context --current --namespace=$NAMESPACE --kubeconfig "${KUBECONFIG}"
        kubectl get dynamographdeployments || true
        kubectl get all || true
        kubectl delete dynamographdeployments --all -n $NAMESPACE || true
        helm uninstall dynamo-platform --namespace $NAMESPACE --timeout 10m || true
        kubectl delete namespace $NAMESPACE || true

  ############################## RESULTS SUMMARY ##############################
  results-summary:
    name: Results Summary
    runs-on: ubuntu-latest
    if: always()
    needs: [vllm-pipeline, sglang-pipeline, trtllm-pipeline, unit-tests, integration-tests, e2e-single-gpu-tests, e2e-multi-gpu-tests, fault-tolerance-tests]
    steps:
      - uses: actions/checkout@v4
      - name: Gather job metadata
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PIPELINE_TYPE: ${{ inputs.pipeline_type }}
        run: |
          set +x -e
          echo "# ${PIPELINE_TYPE^} CI Results Summary" > results.md
          echo "" >> results.md
          echo "| Stage | Status | Runner | Duration (min) | Artifacts |" >> results.md
          echo "|-------|--------|--------|----------------|-----------|" >> results.md

          curl -s -S -L --fail-with-body \
            -H "Authorization: Bearer ${GITHUB_TOKEN}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100" \
            2>/dev/null | jq -c '.jobs[] | {id, name, runner_name, conclusion, started_at, completed_at}' > jobs.jsonl

          while read job_entry; do
            job_id=$(echo "$job_entry" | jq -r '.id')
            name=$(echo "$job_entry" | jq -r '.name')
            runner=$(echo "$job_entry" | jq -r '.runner_name')
            status=$(echo "$job_entry" | jq -r '.conclusion')
            started=$(echo "$job_entry" | jq -r '.started_at')
            completed=$(echo "$job_entry" | jq -r '.completed_at')
            minutes="N/A"
            if [[ "$started" != "null" && "$completed" != "null" ]]; then
              start_epoch=$(date -d "$started" +%s)
              end_epoch=$(date -d "$completed" +%s)
              minutes=$(( (end_epoch - start_epoch)/60 ))
            fi
            artifact_link="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}#job-$job_id"
            printf "| %s | %s | %s | %s | [Log & Artifacts](%s) |\n" "$name" "$status" "$runner" "$minutes" "$artifact_link" >> results.md
          done < jobs.jsonl

          echo "" >> results.md
          echo "---" >> results.md
      - name: Display workflow summary
        run: cat results.md
      - name: Upload results summary as job summary
        run: cat results.md >> $GITHUB_STEP_SUMMARY
      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ inputs.pipeline_type }}-results-summary
          path: results.md
          retention-days: 7

  ############################## SLACK NOTIFICATION ##############################
  notify-slack:
    name: Notify Slack
    runs-on: prod-builder-amd-v1
    if: always() && inputs.enable_slack_notification && !github.event.repository.fork
    needs: results-summary
    permissions:
      contents: read
    env:
      HAS_SLACK_WEBHOOK: ${{ secrets.SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL != '' }}
    steps:
      - name: Send Slack notification
        if: env.HAS_SLACK_WEBHOOK == 'true'
        continue-on-error: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_NOTIFY_NIGHTLY_WEBHOOK_URL }}
          SLACK_OPS_GROUP_ID: ${{ secrets.SLACK_OPS_SUPPORT_GROUP_ID }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          PIPELINE_TYPE: ${{ inputs.pipeline_type }}
        run: |
          set -euo pipefail

          JOBS_JSON=$(mktemp)
          trap 'rm -f "$JOBS_JSON"' EXIT

          if ! curl -sSL \
            -H "Authorization: Bearer ${GITHUB_TOKEN}" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs?per_page=100" \
            > "$JOBS_JSON"; then
            echo "Error: Failed to fetch job data from GitHub API"
            exit 1
          fi

          if [ ! -s "$JOBS_JSON" ]; then
            echo "Error: No job data received"
            exit 1
          fi

          TOTAL_JOBS=$(jq '[.jobs[]] | length' "$JOBS_JSON")
          SUCCESS_COUNT=$(jq '[.jobs[] | select(.conclusion == "success")] | length' "$JOBS_JSON")
          FAILED_COUNT=$(jq '[.jobs[] | select(.conclusion == "failure")] | length' "$JOBS_JSON")

          if [ "$FAILED_COUNT" -eq 0 ]; then
            STATUS="Success"
          else
            STATUS="Failed"
          fi

          DISPLAY_TYPE="${PIPELINE_TYPE^}"
          SUMMARY_TEXT="*${DISPLAY_TYPE} CI Pipeline - ${STATUS}*"$'\n'"Summary: ${SUCCESS_COUNT}/${TOTAL_JOBS} jobs passed"$'\n'"<${RUN_URL}|View Workflow Summary>"

          if [ "$FAILED_COUNT" -eq 0 ]; then
            PAYLOAD=$(jq -n --arg text "$SUMMARY_TEXT" '{text: $text}')
          else
            FAILED_JOBS=$(jq -r '.jobs[] | select(.conclusion == "failure") | "- " + .name' "$JOBS_JSON")
            FAILED_JOBS_TEXT="*Failed Jobs (${FAILED_COUNT}):*"$'\n'"${FAILED_JOBS}"
            if [ -n "${SLACK_OPS_GROUP_ID:-}" ]; then
              OPS_MENTION="<!subteam^${SLACK_OPS_GROUP_ID}|@ops-support>"
            else
              OPS_MENTION="@ops-support"
            fi
            ACTION_TEXT="cc ${OPS_MENTION} - Please investigate the failures above."
            PAYLOAD=$(jq -n \
              --arg summary "$SUMMARY_TEXT" \
              --arg failed "$FAILED_JOBS_TEXT" \
              --arg action "$ACTION_TEXT" \
              '{
                text: $summary,
                blocks: [
                  {type: "section", text: {type: "mrkdwn", text: $summary}},
                  {type: "section", text: {type: "mrkdwn", text: $failed}},
                  {type: "divider"},
                  {type: "context", elements: [{type: "mrkdwn", text: $action}]}
                ]
              }')
          fi

          curl -sSf -X POST -H "Content-Type: application/json" -d "$PAYLOAD" "$SLACK_WEBHOOK_URL" || echo "Warning: Failed to send Slack notification"
