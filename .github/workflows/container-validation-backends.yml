# SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

name: Docker Build and Test

on:
  push:
    branches:
      - main
      - "pull-request/[0-9]+"
      - release/*.*.*

concurrency:
    group: ${{ github.workflow }}-build-test-${{ github.ref_name || github.run_id }}
    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

jobs:
  changed-files:
    runs-on: ubuntu-latest
    outputs:
      has_code_changes: ${{ steps.filter.outputs.has_code_changes }}
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
      - name: Check for changes
        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36  # v3.0.2
        id: filter
        with:
          filters: .github/filters.yaml

  # backend-status-check:
  #   runs-on: ubuntu-latest
  #   needs: [vllm, sglang, trtllm]
  #   if: always()
  #   steps:
  #     - name: "Check all dependent jobs"
  #       run: |
  #         echo '${{ toJson(needs) }}' | jq -e 'to_entries | map(.value.result) | all(. as $result | ["success", "skipped"] | any($result == .))'

  # vllm:
  #   needs: changed-files
  #   if: needs.changed-files.outputs.has_code_changes == 'true'
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       platform:
  #         - { arch: amd64, runner: gpu-l40-amd64 }
  #         - { arch: arm64, runner: cpu-arm-r8g-4xlarge }
  #   name: vllm (${{ matrix.platform.arch }})
  #   runs-on: ${{ matrix.platform.runner }}
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
  #     - name: Build Container
  #       id: build-image
  #       uses: ./.github/actions/docker-build
  #       with:
  #         framework: vllm
  #         target: runtime
  #         platform: 'linux/${{ matrix.platform.arch }}'
  #         ngc_ci_access_token: ${{ secrets.NGC_CI_ACCESS_TOKEN }}
  #         ci_token: ${{ secrets.CI_TOKEN }}
  #         aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
  #         sccache_s3_bucket: ${{ secrets.SCCACHE_S3_BUCKET }}
  #         aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #         aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #     - name: Docker Tag and Push
  #       uses: ./.github/actions/docker-tag-push
  #       with:
  #         local_image: ${{ steps.build-image.outputs.image_tag }}
  #         push_tag: ai-dynamo/dynamo:${{ github.sha }}-vllm-${{ matrix.platform.arch }}
  #         # OPS-1145: Switch aws_push to true
  #         aws_push: 'false'
  #         azure_push: 'true'
  #         aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
  #         aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
  #         azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
  #         azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
  #         azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}

  #     - name: Run unit tests
  #       if: ${{ matrix.platform.arch != 'arm64' }}
  #       uses: ./.github/actions/pytest
  #       with:
  #         image_tag: ${{ steps.build-image.outputs.image_tag }}
  #         pytest_marks: "unit and vllm and gpu_1"
  #     - name: Run e2e tests
  #       if: ${{ matrix.platform.arch != 'arm64' }}
  #       uses: ./.github/actions/pytest
  #       with:
  #         image_tag: ${{ steps.build-image.outputs.image_tag }}
  #         pytest_marks: "e2e and vllm and gpu_1 and not slow"

  # sglang:
  #   needs: changed-files
  #   if: needs.changed-files.outputs.has_code_changes == 'true'
  #   # OPS-1140: Uncomment this for sglang arm switch to wideep
  #   # strategy:
  #   #   fail-fast: false
  #   #   matrix:
  #   #     platform:
  #   #       - { arch: amd64, runner: gpu-l40-amd64 }
  #   #       - { arch: arm64, runner: cpu-arm-r8g-4xlarge }
  #   # name: sglang (${{ matrix.platform.arch }})
  #   # runs-on: ${{ matrix.platform.runner }}
  #   # OPS-1140: Remove this runs-on line, replaced with the above line
  #   runs-on: gpu-l40-amd64
  #   steps:
  #     - name: Checkout repository
  #       uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0

  #     - name: Build Container
  #       id: build-image
  #       uses: ./.github/actions/docker-build
  #       with:
  #         framework: sglang
  #         target: runtime
  #         platform: 'linux/amd64'
  #         # OPS-1140: Replace the above line with the uncommented below line
  #         # platform: 'linux/${{ matrix.platform.arch }}'
  #         ngc_ci_access_token: ${{ secrets.NGC_CI_ACCESS_TOKEN }}
  #         ci_token: ${{ secrets.CI_TOKEN }}
  #         aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
  #         sccache_s3_bucket: ${{ secrets.SCCACHE_S3_BUCKET }}
  #         aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #         aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

  #     - name: Docker Tag and Push
  #       uses: ./.github/actions/docker-tag-push
  #       with:
  #         local_image: ${{ steps.build-image.outputs.image_tag }}
  #         push_tag: ai-dynamo/dynamo:${{ github.sha }}-sglang-amd64
  #         # OPS-1140: Replace the above line with the uncommented below line
  #         # push_tag: ai-dynamo/dynamo:${{ github.sha }}-sglang-${{ matrix.platform.arch }}
  #         # OPS-1145: Switch aws_push to true
  #         aws_push: 'false'
  #         azure_push: 'true'
  #         aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
  #         aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
  #         azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
  #         azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
  #         azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}

  #     - name: Run unit tests
  #       # OPS-1140: Uncomment the below line
  #       # if: ${{ matrix.platform.arch != 'arm64' }}
  #       uses: ./.github/actions/pytest
  #       with:
  #         image_tag: ${{ steps.build-image.outputs.image_tag }}
  #         pytest_marks: "unit and sglang and gpu_1"
  #     - name: Run e2e tests
  #       # OPS-1140: Uncomment the below line
  #       # if: ${{ matrix.platform.arch != 'arm64' }}
  #       uses: ./.github/actions/pytest
  #       with:
  #         image_tag: ${{ steps.build-image.outputs.image_tag }}
  #         pytest_marks: "e2e and sglang and gpu_1"

  # trtllm:
  #   needs: changed-files
  #   if: needs.changed-files.outputs.has_code_changes == 'true'
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       platform:
  #         - { arch: amd64, runner: gpu-l40-amd64 }
  #         - { arch: arm64, runner: cpu-arm-r8g-4xlarge }
  #   name: trtllm (${{ matrix.platform.arch }})
  #   runs-on: ${{ matrix.platform.runner }}
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0

  #     - name: Build Container
  #       id: build-image
  #       uses: ./.github/actions/docker-build
  #       with:
  #         framework: trtllm
  #         target: runtime
  #         platform: 'linux/${{ matrix.platform.arch }}'
  #         ngc_ci_access_token: ${{ secrets.NGC_CI_ACCESS_TOKEN }}
  #         ci_token: ${{ secrets.CI_TOKEN }}
  #         aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
  #         sccache_s3_bucket: ${{ secrets.SCCACHE_S3_BUCKET }}
  #         aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #         aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

  #     - name: Docker Tag and Push
  #       uses: ./.github/actions/docker-tag-push
  #       with:
  #         local_image: ${{ steps.build-image.outputs.image_tag }}
  #         push_tag: ai-dynamo/dynamo:${{ github.sha }}-trtllm-${{ matrix.platform.arch }}
  #         # OPS-1145: Switch aws_push to true
  #         aws_push: 'false'
  #         azure_push: 'true'
  #         aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
  #         aws_default_region: ${{ secrets.AWS_DEFAULT_REGION }}
  #         azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
  #         azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
  #         azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}

  #     - name: Run unit tests
  #       if: ${{ matrix.platform.arch != 'arm64' }}
  #       uses: ./.github/actions/pytest
  #       with:
  #         image_tag: ${{ steps.build-image.outputs.image_tag }}
  #         pytest_marks: "unit and trtllm_marker and gpu_1"
  #     - name: Run e2e tests
  #       if: ${{ matrix.platform.arch != 'arm64' }}
  #       uses: ./.github/actions/pytest
  #       with:
  #         image_tag: ${{ steps.build-image.outputs.image_tag }}
  #         pytest_marks: "e2e and trtllm_marker and gpu_1 and not slow"

  # # Upload metrics for this workflow and all its jobs
  # upload-workflow-metrics:
  #   name: Upload Workflow Metrics
  #   runs-on: gitlab
  #   if: always()  # Always run, even if other jobs fail
  #   needs: [backend-status-check]  # Wait for the status check which waits for all build jobs

  #   steps:
  #     - name: Check out repository
  #       uses: actions/checkout@v4

  #     - name: Set up Python
  #       uses: actions/setup-python@v4
  #       with:
  #         python-version: '3.x'

  #     - name: Install dependencies
  #       run: |
  #         python -m pip install --upgrade pip
  #         pip install requests

  #     - name: Download build metrics
  #       uses: actions/download-artifact@v4
  #       with:
  #         pattern: build-metrics-*
  #         path: build-metrics/
  #         merge-multiple: true
  #       continue-on-error: true  # Don't fail if artifacts don't exist

  #     - name: Upload Complete Workflow Metrics
  #       env:
  #         GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  #         WORKFLOW_INDEX: ${{ secrets.WORKFLOW_INDEX }}
  #         JOB_INDEX: ${{ secrets.JOB_INDEX }}
  #         STEPS_INDEX: ${{ secrets.STEPS_INDEX }}
  #         # Container index configuration
  #         CONTAINER_INDEX: ${{ secrets.CONTAINER_INDEX }}
  #       run: |
  #         # Upload complete workflow metrics including container metrics
  #         python3 .github/workflows/upload_complete_workflow_metrics.py

  build-operator:
    runs-on: gpu-l40-amd64
    steps:
      - name: Checkout code
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955  # v4.3.0
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Build Container
        id: build-image
        run: |
          cd deploy/cloud/operator
          docker build -f Dockerfile -t dynamo-operator:latest .
      - name: Docker Tag and Push
        uses: ./.github/actions/docker-tag-push
        with:
          local_image: dynamo-operator:latest
          push_tag: ai-dynamo/dynamo:${{ github.sha }}-operator-amd64
          aws_push: 'true'
          azure_push: 'true'
          aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
          aws_default_region: us-west-2
          azure_acr_hostname: ${{ secrets.AZURE_ACR_HOSTNAME }}
          azure_acr_user: ${{ secrets.AZURE_ACR_USER }}
          azure_acr_password: ${{ secrets.AZURE_ACR_PASSWORD }}

  deploy-test:
    runs-on: cpu-amd-m5-2xlarge
    needs: [build-operator]
    permissions:
      contents: read
    env:
      NAMESPACE: gh-job-id-${{ github.run_id }}
      DYNAMO_INGRESS_SUFFIX: dev.aire.nvidia.com
      DEPLOYMENT_FILE: "deploy/disagg.yaml"
      MODEL_NAME: "Qwen/Qwen3-0.6B"
      KUBECONFIG_PATH: .kubeconfig
      POD_READY_TIMEOUT: 1000s
      DEPLOYMENT_READY_TIMEOUT: 300s
      MODEL_WAIT_MAX_ATTEMPTS: 30
      MODEL_WAIT_INTERVAL: 5
      PORT_FORWARD_WAIT: 10
      NAMESPACE_CLEANUP_DELAY: 30
    steps:
    - uses: actions/checkout@v4

    - name: Install dependencies
      run: |
        set -euo pipefail

        echo "Installing system dependencies..."
        sudo apt-get update && sudo apt-get install -y curl bash openssl gettext git jq

        echo "Installing yq..."
        curl -fsSL https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -o yq
        sudo install -m 755 yq /usr/local/bin/yq
        rm yq

        echo "Installing Helm..."
        curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

        echo "Installing kubectl..."
        KUBECTL_VERSION=$(curl -L -s https://dl.k8s.io/release/stable.txt)
        curl -fsSL "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl" -o kubectl
        sudo install -m 755 kubectl /usr/local/bin/kubectl
        rm kubectl

        echo "Verifying installations..."
        yq --version
        helm version
        kubectl version --client

    - name: Setup Kubernetes config
      run: |
        set -euo pipefail

        echo "Setting up kubeconfig..."
        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > "${KUBECONFIG_PATH}"
        chmod 600 "${KUBECONFIG_PATH}"

        export KUBECONFIG="${PWD}/${KUBECONFIG_PATH}"
        kubectl config set-context --current --namespace="${NAMESPACE}"

        echo "Current context:"
        kubectl config current-context
        kubectl cluster-info

    - name: Create namespace and setup cluster
      run: |
        set -euo pipefail
        export KUBECONFIG="${PWD}/${KUBECONFIG_PATH}"

        echo "Creating ephemeral namespace: ${NAMESPACE}..."
        kubectl delete namespace "${NAMESPACE}" --ignore-not-found=true --timeout=60s
        kubectl create namespace "${NAMESPACE}"

        echo "Applying namespace labels..."
        kubectl label namespace "${NAMESPACE}" \
          nscleanup/enabled=true \
          nscleanup/ttl=7200 \
          gitlab-imagepull=enabled \
          ngc-api=enabled \
          nvcr-imagepull=enabled \
          --overwrite=true

        kubectl config set-context --current --namespace="${NAMESPACE}"

        echo "Verifying cluster prerequisites..."
        kubectl get pods -n istio-system
        kubectl get storageclass

    - name: Create secrets
      run: |
        set -euo pipefail
        export KUBECONFIG="${PWD}/${KUBECONFIG_PATH}"

        echo "Creating HuggingFace token secret..."
        kubectl create secret generic hf-token-secret \
          --from-literal=HF_TOKEN="${{ secrets.HF_TOKEN }}" \
          -n "${NAMESPACE}" \
          --dry-run=client -o yaml | kubectl apply -f -

        echo "Creating Docker registry secret..."
        kubectl create secret docker-registry docker-imagepullsecret \
          --docker-server="${{ secrets.AZURE_ACR_HOSTNAME }}" \
          --docker-username="${{ secrets.AZURE_ACR_USER }}" \
          --docker-password="${{ secrets.AZURE_ACR_PASSWORD }}" \
          --namespace="${NAMESPACE}" \
          --dry-run=client -o yaml | kubectl apply -f -

    - name: Deploy Dynamo Platform
      run: |
        set -euo pipefail
        export KUBECONFIG="${PWD}/${KUBECONFIG_PATH}"

        echo "Adding Helm repositories..."
        helm repo add bitnami https://charts.bitnami.com/bitnami
        helm repo update

        echo "Building Helm dependencies..."
        cd deploy/cloud/helm/platform/
        helm dependency build .

        echo "Installing Dynamo Platform..."
        helm upgrade --install dynamo-platform . \
          --namespace "${NAMESPACE}" \
          --set dynamo-operator.namespaceRestriction.enabled=true \
          --set dynamo-operator.namespaceRestriction.allowedNamespaces[0]="${NAMESPACE}" \
          --set dynamo-operator.controllerManager.manager.image.repository="${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo" \
          --set dynamo-operator.controllerManager.manager.image.tag="${{ github.sha }}-operator-amd64" \
          --set dynamo-operator.imagePullSecrets[0].name=docker-imagepullsecret \
          --wait \
          --timeout=10m

        cd -

        echo "Waiting for platform deployments to be ready..."
        timeout "${DEPLOYMENT_READY_TIMEOUT}" kubectl rollout status deployment -n "${NAMESPACE}" --watch

        echo "Platform deployment complete. Current resources:"
        kubectl get all -n "${NAMESPACE}"

    - name: Deploy backend service
      run: |
        set -euo pipefail
        export KUBECONFIG="${PWD}/${KUBECONFIG_PATH}"

        FRAMEWORK_RUNTIME_IMAGE="${{ secrets.AZURE_ACR_HOSTNAME }}/ai-dynamo/dynamo:f0d1f14651c94d1134f568ccfd24a7d09369226e-vllm-amd64"

        cd components/backends/vllm

        GRAPH_NAME=$(yq e '.metadata.name' "${DEPLOYMENT_FILE}")
        echo "Deploying backend service: ${GRAPH_NAME}"
        echo "Using image: ${FRAMEWORK_RUNTIME_IMAGE}"

        # Update deployment file with runtime image
        yq eval -i ".spec.services.[].extraPodSpec.mainContainer.image = \"${FRAMEWORK_RUNTIME_IMAGE}\"" "${DEPLOYMENT_FILE}"

        echo "=== Updated Deployment File ==="
        cat "${DEPLOYMENT_FILE}"
        echo "==============================="

        echo "Applying deployment..."
        kubectl apply -n "${NAMESPACE}" -f "${DEPLOYMENT_FILE}"

        echo "Waiting for pods to initialize..."
        sleep 20

        echo "Waiting for pods with label nvidia.com/dynamo-graph-deployment-name=${GRAPH_NAME}..."
        kubectl wait --for=condition=ready \
          pod -l "nvidia.com/dynamo-graph-deployment-name=${GRAPH_NAME}" \
          -n "${NAMESPACE}" \
          --timeout="${POD_READY_TIMEOUT}"

        echo "=== Backend Service Pod Status ==="
        kubectl get pods -l "nvidia.com/dynamo-graph-deployment-name=${GRAPH_NAME}" \
          -n "${NAMESPACE}" -o wide
        echo "==================================="

        cd -

    - name: Test backend service
      run: |
        set -euo pipefail
        export KUBECONFIG="${PWD}/${KUBECONFIG_PATH}"

        echo "Finding frontend pod..."
        FRONTEND_POD=$(kubectl get pods -n "${NAMESPACE}" -l app=frontend --no-headers | sort -k1 | tail -n1 | awk '{print $1}')

        if [ -z "${FRONTEND_POD}" ]; then
          echo "ERROR: Frontend pod not found"
          kubectl get pods -n "${NAMESPACE}"
          exit 1
        fi

        echo "Frontend pod: ${FRONTEND_POD}"

        CONTAINER_PORT=$(kubectl get pod "${FRONTEND_POD}" -n "${NAMESPACE}" \
          -o jsonpath='{.spec.containers[0].ports[?(@.name=="http")].containerPort}')
        echo "Container port: ${CONTAINER_PORT}"

        echo "Setting up port forwarding..."
        kubectl port-forward "pod/${FRONTEND_POD}" "8000:${CONTAINER_PORT}" -n "${NAMESPACE}" &
        PORT_FORWARD_PID=$!

        sleep "${PORT_FORWARD_WAIT}"

        LLM_URL="http://localhost:8000"
        echo "LLM URL: ${LLM_URL}"
        echo "Model Name: ${MODEL_NAME}"

        # Wait for model to be available
        echo "Waiting for model ${MODEL_NAME} to be available..."
        ATTEMPT=1
        while [ ${ATTEMPT} -le ${MODEL_WAIT_MAX_ATTEMPTS} ]; do
          MODELS_RESPONSE=$(curl -s --retry 5 --retry-delay 2 --retry-connrefused "${LLM_URL}/v1/models" || echo "{}")

          if echo "${MODELS_RESPONSE}" | jq -e --arg MODEL_NAME "${MODEL_NAME}" '.data[]?.id == $MODEL_NAME' >/dev/null 2>&1; then
            echo "✓ Model ${MODEL_NAME} is available"
            break
          fi

          echo "Waiting for model ${MODEL_NAME}... (attempt ${ATTEMPT}/${MODEL_WAIT_MAX_ATTEMPTS})"
          sleep "${MODEL_WAIT_INTERVAL}"
          ATTEMPT=$((ATTEMPT + 1))
        done

        if [ ${ATTEMPT} -gt ${MODEL_WAIT_MAX_ATTEMPTS} ]; then
          echo "ERROR: Model ${MODEL_NAME} not found after ${MODEL_WAIT_MAX_ATTEMPTS} attempts"
          echo "Last response: ${MODELS_RESPONSE}"
          kill ${PORT_FORWARD_PID} 2>/dev/null || true
          exit 1
        fi

        # Test inference
        echo "Testing inference..."
        RESPONSE=$(curl -s -N --no-buffer --retry 10 --retry-delay 5 --retry-connrefused \
          -X POST "${LLM_URL}/v1/chat/completions" \
          -H 'accept: text/event-stream' \
          -H 'Content-Type: application/json' \
          -d '{
            "model": "'"${MODEL_NAME:-Qwen/Qwen3-0.6B}"'",
            "messages": [{
              "role": "user",
              "content": "In the heart of Eldoria, an ancient land of boundless magic and mysterious creatures, lies the long-forgotten city of Aeloria. Once a beacon of knowledge and power, Aeloria was buried beneath the shifting sands of time, lost to the world for centuries. You are an intrepid explorer, known for your unparalleled curiosity and courage, who has stumbled upon an ancient map hinting at ests that Aeloria holds a secret so profound that it has the potential to reshape the very fabric of reality. Your journey will take you through treacherous deserts, enchanted forests, and across perilous mountain ranges. Your Task: Character Background: Develop a detailed background for your character. Describe their motivations for seeking out Aeloria, their skills and weaknesses, and any personal connections to the ancient city or its legends. Are they driven by a quest for knowledge, a search for lost familt clue is hidden."
            }],
            "stream": false,
            "max_tokens": 30,
            "temperature": 0.0
          }' 2>&1)

        # Cleanup port forward
        kill ${PORT_FORWARD_PID} 2>/dev/null || true

        echo "=== Response ==="
        echo "${RESPONSE}"
        echo "================"

        # Validate response
        TEST_RESULT=0

        if ! echo "${RESPONSE}" | jq -e . >/dev/null 2>&1; then
          echo "✗ Test failed: Response is not valid JSON"
          TEST_RESULT=1
        elif ! echo "${RESPONSE}" | jq -e '.choices[0].message.role == "assistant"' >/dev/null 2>&1; then
          echo "✗ Test failed: Message role is not 'assistant'"
          echo "Got: $(echo "${RESPONSE}" | jq -r '.choices[0].message.role')"
          TEST_RESULT=1
        elif ! echo "${RESPONSE}" | jq -e '.model == "'"${MODEL_NAME}"'"' >/dev/null 2>&1; then
          echo "✗ Test failed: Model name is incorrect"
          echo "Got: $(echo "${RESPONSE}" | jq -r '.model')"
          TEST_RESULT=1
        elif ! echo "${RESPONSE}" | jq -e '.choices[0].message.content | length > 100' >/dev/null 2>&1; then
          echo "✗ Test failed: Response content length is not greater than 100 characters"
          echo "Got length: $(echo "${RESPONSE}" | jq -r '.choices[0].message.content | length')"
          TEST_RESULT=1
        else
          echo "✓ All tests passed: Response matches expected format and content"
        fi

        exit ${TEST_RESULT}

    - name: Cleanup
      if: always()
      timeout-minutes: 10
      run: |
        set -euo pipefail

        echo "Setting up kubeconfig for cleanup..."
        echo "${{ secrets.AZURE_AKS_CI_KUBECONFIG_B64 }}" | base64 -d > "${KUBECONFIG_PATH}"
        chmod 600 "${KUBECONFIG_PATH}"
        export KUBECONFIG="${PWD}/${KUBECONFIG_PATH}"
        kubectl config set-context --current --namespace="${NAMESPACE}"

        echo "=== Current Resources in ${NAMESPACE} ==="
        kubectl get all -n "${NAMESPACE}" || true
        echo "=========================================="

        echo "Waiting ${NAMESPACE_CLEANUP_DELAY}s before cleanup..."
        sleep "${NAMESPACE_CLEANUP_DELAY}"

        echo "Deleting DynamoGraphDeployments..."
        kubectl delete dynamographdeployments --all -n "${NAMESPACE}" --timeout=120s --ignore-not-found=true || true

        echo "Uninstalling Helm chart..."
        helm list -n "${NAMESPACE}"
        helm uninstall dynamo-platform -n "${NAMESPACE}" --timeout=5m || true

        echo "Deleting namespace ${NAMESPACE}..."
        kubectl delete namespace "${NAMESPACE}" --timeout=120s --ignore-not-found=true || true

        echo "Cleanup completed for namespace ${NAMESPACE}"