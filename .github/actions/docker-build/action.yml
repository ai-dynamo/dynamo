name: 'Docker Build'
description: 'Build Dynamo container images'
inputs:
  framework:
    description: 'Framework to build'
    required: true
    default: 'vllm'
  target:
    description: 'Target to build'
    required: false
    default: 'runtime'
  platform:
    description: 'Docker platform to build on, ie. linux/amd64'
    required: false
    default: 'linux/amd64'
  image_tag:
    description: 'Custom image tag (optional, defaults to framework:latest)'
    required: false
  ngc_ci_access_token:
    description: 'NGC CI Access Token'
    required: false
  ci_token:
    description: 'CI Token'
    required: false
  aws_default_region:
    description: 'AWS Default Region'
    required: false
  sccache_s3_bucket:
    description: 'SCCache S3 Bucket'
    required: false
  aws_account_id:
    description: 'AWS Account ID'
    required: false
  aws_access_key_id:
    description: 'AWS Access Key ID'
    required: false
  aws_secret_access_key:
    description: 'AWS Secret Access Key'
    required: false
  base_image_tag:
    description: 'Optional override for base image tag passed to build.sh'
    required: false
  runtime_image_tag:
    description: 'Optional override for RUNTIME_IMAGE_TAG build-arg'
    required: false
  cuda_version:
    description: 'Optional override for CUDA_VERSION build-arg'
    required: false
  torch_backend:
    description: 'Optional override for TORCH_BACKEND build-arg (e.g., cu129)'
    required: false

outputs:
  image_tag:
    description: 'Image Tag'
    value: ${{ steps.build.outputs.image_tag }}

runs:
  using: "composite"
  steps:
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 #v3.11.1
      with:
        driver: docker
    - name: Login to ECR
      shell: bash
      env:
        ECR_HOSTNAME: ${{ inputs.aws_account_id }}.dkr.ecr.${{ inputs.aws_default_region }}.amazonaws.com
      run: |
        aws ecr get-login-password --region ${{ inputs.aws_default_region }} | docker login --username AWS --password-stdin ${ECR_HOSTNAME}
    - name: Login to NGC
      if: github.event.pull_request.head.repo.full_name == github.repository || github.event_name == 'push'
      shell: bash
      run: |
        echo "${{ inputs.ngc_ci_access_token }}" | docker login nvcr.io -u '$oauthtoken' --password-stdin
    - name: Cleanup
      if: always()
      shell: bash
      run: |
        docker system prune -af
    - name: Build image
      id: build
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.ci_token }}
        AWS_DEFAULT_REGION: ${{ inputs.aws_default_region }}
        SCCACHE_S3_BUCKET:  ${{ inputs.sccache_s3_bucket }}
        AWS_ACCESS_KEY_ID: ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        PLATFORM: ${{ inputs.platform }}
      run: |
        echo "=========================================="
        echo "üöÄ DOCKER BUILD - STARTING"
        echo "=========================================="
        
        # Determine image tag
        if [ -n "${{ inputs.image_tag }}" ]; then
          IMAGE_TAG="${{ inputs.image_tag }}"
        else
          IMAGE_TAG="${{ inputs.framework }}:latest"
        fi
        
        echo "üì¶ Image Tag: ${IMAGE_TAG}"
        echo "üîß Framework: ${{ inputs.framework }}"
        echo "üéØ Target: ${{ inputs.target }}"
        echo "üíª Platform: ${{ inputs.platform }}"
        echo "üîê Using sccache: ${{ inputs.sccache_s3_bucket != '' && 'true' || 'false' }}"

        BUILD_START_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)
        BUILD_START_EPOCH=$(date +%s)
        echo "üïê Build started at: ${BUILD_START_TIME} (epoch: ${BUILD_START_EPOCH})"
        echo "BUILD_START_TIME=${BUILD_START_TIME}" >> $GITHUB_ENV
        echo "BUILD_START_EPOCH=${BUILD_START_EPOCH}" >> $GITHUB_ENV

        echo "image_tag=$IMAGE_TAG" >> $GITHUB_OUTPUT
        
        # Create build logs directory
        mkdir -p build-logs
        BUILD_LOG_FILE="build-logs/build-${{ inputs.framework }}-$(echo '${{ inputs.platform }}' | sed 's/linux\///').log"
        echo "BUILD_LOG_FILE=${BUILD_LOG_FILE}" >> $GITHUB_ENV
        echo "üìù Build log will be saved to: ${BUILD_LOG_FILE}"
        
        # Collect optional overrides provided by the workflow
        EXTRA_ARGS=""
        if [ -n "${{ inputs.base_image_tag }}" ]; then
          EXTRA_ARGS+=" --base-image-tag ${{ inputs.base_image_tag }}"
          echo "üîß Base Image Tag Override: ${{ inputs.base_image_tag }}"
        fi
        if [ -n "${{ inputs.runtime_image_tag }}" ]; then
          EXTRA_ARGS+=" --build-arg RUNTIME_IMAGE_TAG=${{ inputs.runtime_image_tag }}"
          echo "üîß Runtime Image Tag Override: ${{ inputs.runtime_image_tag }}"
        fi
        if [ -n "${{ inputs.cuda_version }}" ]; then
          EXTRA_ARGS+=" --build-arg CUDA_VERSION=${{ inputs.cuda_version }}"
          echo "üîß CUDA Version Override: ${{ inputs.cuda_version }}"
        fi
        if [ -n "${{ inputs.torch_backend }}" ]; then
          EXTRA_ARGS+=" --build-arg TORCH_BACKEND=${{ inputs.torch_backend }}"
          echo "üîß Torch Backend Override: ${{ inputs.torch_backend }}"
        fi
        
        echo ""
        echo "üìã Build command:"
        echo "  ./container/build.sh --tag \"${IMAGE_TAG}\" \\"
        echo "    --target ${{ inputs.target }} \\"
        echo "    --vllm-max-jobs 10 \\"
        echo "    --framework ${{ inputs.framework }} \\"
        echo "    --platform ${{ inputs.platform }} \\"
        echo "    --use-sccache \\"
        echo "    --sccache-bucket \"${SCCACHE_S3_BUCKET}\" \\"
        echo "    --sccache-region \"${AWS_DEFAULT_REGION}\" ${EXTRA_ARGS}"
        echo ""
        echo "=========================================="
        echo "üèóÔ∏è  EXECUTING BUILD"
        echo "=========================================="

        # Execute build and capture output (show on console AND save to file)
        ./container/build.sh --tag "$IMAGE_TAG" \
          --target ${{ inputs.target }} \
          --vllm-max-jobs 10 \
          --framework ${{ inputs.framework }} \
          --platform ${{ inputs.platform }} \
          --use-sccache \
          --sccache-bucket "$SCCACHE_S3_BUCKET" \
          --sccache-region "$AWS_DEFAULT_REGION" $EXTRA_ARGS 2>&1 | tee "${BUILD_LOG_FILE}"
        
        BUILD_EXIT_CODE=${PIPESTATUS[0]}
        
        BUILD_END_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)
        BUILD_END_EPOCH=$(date +%s)
        BUILD_DURATION=$((BUILD_END_EPOCH - BUILD_START_EPOCH))
        
        echo ""
        echo "=========================================="
        echo "‚úÖ BUILD COMPLETED"
        echo "=========================================="
        echo "üïê Build ended at: ${BUILD_END_TIME} (epoch: ${BUILD_END_EPOCH})"
        echo "‚è±Ô∏è  Total build duration: ${BUILD_DURATION} seconds"
        echo "üìù Build log saved to: ${BUILD_LOG_FILE}"
        echo "üìä Build log size: $(wc -l < "${BUILD_LOG_FILE}") lines, $(du -h "${BUILD_LOG_FILE}" | cut -f1)"
        echo "üéØ Exit code: ${BUILD_EXIT_CODE}"
        
        echo "BUILD_END_TIME=${BUILD_END_TIME}" >> $GITHUB_ENV
        echo "BUILD_END_EPOCH=${BUILD_END_EPOCH}" >> $GITHUB_ENV
        
        # Exit with the build's exit code
        exit ${BUILD_EXIT_CODE}

    - name: Capture Build Metrics
      id: metrics
      shell: bash
      run: |
        echo "=========================================="
        echo "üìä CAPTURING BUILD METRICS"
        echo "=========================================="
        echo "Framework: ${{ inputs.framework }}"
        echo "Platform: ${{ inputs.platform }}"

        # Create metrics directory
        mkdir -p build-metrics

        # Get accurate build timing
        BUILD_START_TIME="${{ env.BUILD_START_TIME }}"
        BUILD_END_TIME="${{ env.BUILD_END_TIME }}"
        BUILD_LOG_FILE="${{ env.BUILD_LOG_FILE }}"

        # Calculate duration
        START_EPOCH=$(date -d "$BUILD_START_TIME" +%s)
        END_EPOCH=$(date -d "$BUILD_END_TIME" +%s)
        BUILD_DURATION_SEC=$((END_EPOCH - START_EPOCH))

        echo ""
        echo "üïê Build timing:"
        echo "  Start: ${BUILD_START_TIME}"
        echo "  End: ${BUILD_END_TIME}"
        echo "  Duration: ${BUILD_DURATION_SEC} seconds"

        # Get image size using docker inspect
        IMAGE_TAG="${{ steps.build.outputs.image_tag }}"
        if [ -n "$IMAGE_TAG" ]; then
          IMAGE_SIZE_BYTES=$(docker image inspect "$IMAGE_TAG" --format='{{.Size}}' 2>/dev/null || echo "0")
          echo ""
          echo "üì¶ Image size: ${IMAGE_SIZE_BYTES} bytes ($(numfmt --to=iec-i --suffix=B ${IMAGE_SIZE_BYTES} 2>/dev/null || echo 'N/A'))"
        else
          IMAGE_SIZE_BYTES=0
          echo ""
          echo "‚ö†Ô∏è  No image tag available"
        fi
        
        # Parse build log for additional metrics
        echo ""
        echo "üìù Analyzing build log: ${BUILD_LOG_FILE}"
        
        CACHED_LAYERS=0
        TOTAL_STEPS=0
        BUILD_WARNINGS=0
        BUILD_ERRORS=0
        PULL_OPERATIONS=0
        
        if [ -f "${BUILD_LOG_FILE}" ]; then
          # Count cached layers
          CACHED_LAYERS=$(grep -c "CACHED" "${BUILD_LOG_FILE}" 2>/dev/null || echo "0")
          
          # Count total build steps
          TOTAL_STEPS=$(grep -c "^Step [0-9]" "${BUILD_LOG_FILE}" 2>/dev/null || echo "0")
          
          # Count warnings and errors
          BUILD_WARNINGS=$(grep -ci "warning" "${BUILD_LOG_FILE}" 2>/dev/null || echo "0")
          BUILD_ERRORS=$(grep -ci "error" "${BUILD_LOG_FILE}" 2>/dev/null || echo "0")
          
          # Count pull operations
          PULL_OPERATIONS=$(grep -c "Pulling from\|Pull complete" "${BUILD_LOG_FILE}" 2>/dev/null || echo "0")
          
          echo "  üìä Cached layers: ${CACHED_LAYERS}"
          echo "  üìä Total build steps: ${TOTAL_STEPS}"
          echo "  ‚ö†Ô∏è  Warnings: ${BUILD_WARNINGS}"
          echo "  ‚ùå Errors: ${BUILD_ERRORS}"
          echo "  üì• Pull operations: ${PULL_OPERATIONS}"
          
          # Calculate cache hit rate
          if [ ${TOTAL_STEPS} -gt 0 ]; then
            CACHE_HIT_RATE=$(awk "BEGIN {printf \"%.2f\", (${CACHED_LAYERS} / ${TOTAL_STEPS}) * 100}")
            echo "  üìà Cache hit rate: ${CACHE_HIT_RATE}%"
          else
            CACHE_HIT_RATE="0"
          fi
        else
          echo "  ‚ö†Ô∏è  Build log file not found"
          CACHE_HIT_RATE="0"
        fi

        echo ""
        echo "üîç Platform information:"
        PLATFORM_ARCH=$(echo "${{ inputs.platform }}" | sed 's/linux\///')
        echo "  Architecture: ${PLATFORM_ARCH}"
        echo "PLATFORM_ARCH=${PLATFORM_ARCH}" >> $GITHUB_ENV
        JOB_KEY="${{ inputs.framework }}-${PLATFORM_ARCH}"
        echo "  Job Key: ${JOB_KEY}"

        # Create job-specific metrics file
        mkdir -p build-metrics
        METRICS_FILE="build-metrics/metrics-${{ inputs.framework }}-${PLATFORM_ARCH}-${{ github.run_id }}-${{ job.check_run_id }}.json"

        echo ""
        echo "üíæ Writing metrics to: ${METRICS_FILE}"
        
        # Create the job metrics file with enhanced metrics
        cat > "$METRICS_FILE" << EOF
        {
          "framework": "${{ inputs.framework }}",
          "target": "${{ inputs.target }}",
          "platform": "${{ inputs.platform }}",
          "platform_arch": "${PLATFORM_ARCH}",
          "image_size_bytes": ${IMAGE_SIZE_BYTES},
          "build_start_time": "${BUILD_START_TIME}",
          "build_end_time": "${BUILD_END_TIME}",
          "build_duration_sec": ${BUILD_DURATION_SEC},
          "cached_layers": ${CACHED_LAYERS},
          "total_build_steps": ${TOTAL_STEPS},
          "cache_hit_rate_percent": ${CACHE_HIT_RATE},
          "build_warnings": ${BUILD_WARNINGS},
          "build_errors": ${BUILD_ERRORS},
          "pull_operations": ${PULL_OPERATIONS}
        }
        EOF

        echo ""
        echo "üìÑ Metrics file contents:"
        cat "$METRICS_FILE"

        echo ""
        echo "‚úÖ Metrics captured and saved successfully"
        echo "=========================================="

    - name: Collect Layer Metrics
      id: layer-metrics
      shell: bash
      run: |
        echo "=========================================="
        echo "üîç COLLECTING LAYER-LEVEL METRICS"
        echo "=========================================="
        echo "Framework: ${{ inputs.framework }}"
        
        IMAGE_TAG="${{ steps.build.outputs.image_tag }}"
        PLATFORM_ARCH="${{ env.PLATFORM_ARCH }}"
        BUILD_LOG_FILE="${{ env.BUILD_LOG_FILE }}"
        
        echo "Image Tag: ${IMAGE_TAG}"
        echo "Platform: ${PLATFORM_ARCH}"
        echo "Build Log: ${BUILD_LOG_FILE}"
        echo ""
        
        if [ -z "$IMAGE_TAG" ]; then
          echo "‚ö†Ô∏è  No image tag available, skipping layer metrics collection"
          exit 0
        fi
        
        # Verify image exists
        echo "üîç Verifying image exists..."
        if ! docker image inspect "$IMAGE_TAG" &> /dev/null; then
          echo "‚ùå Image not found: $IMAGE_TAG"
          echo "Available images:"
          docker images
          exit 1
        fi
        echo "‚úÖ Image verified"
        echo ""
        
        # Install Python if needed (usually available in GitHub runners)
        if ! command -v python3 &> /dev/null; then
          echo "üì¶ Python3 not found, installing..."
          sudo apt-get update && sudo apt-get install -y python3
        else
          echo "‚úÖ Python3 found: $(python3 --version)"
        fi
        echo ""
        
        # Create layer metrics directory
        mkdir -p build-metrics/layers
        
        # Run layer metrics collection script
        LAYER_METRICS_FILE="build-metrics/layers/layer-metrics-${{ inputs.framework }}-${PLATFORM_ARCH}-${{ github.run_id }}-${{ job.check_run_id }}.json"
        
        echo "üöÄ Running layer metrics collection..."
        echo "Output file: ${LAYER_METRICS_FILE}"
        echo ""
        
        # Make script executable
        chmod +x .github/scripts/collect_layer_metrics.py
        
        # Run with explicit error handling
        set +e
        python3 .github/scripts/collect_layer_metrics.py \
          "$IMAGE_TAG" \
          "${{ inputs.framework }}" \
          "${PLATFORM_ARCH}" \
          "$LAYER_METRICS_FILE"
        COLLECTION_EXIT_CODE=$?
        set -e
        
        echo ""
        echo "üìä Collection exit code: ${COLLECTION_EXIT_CODE}"
        
        if [ ${COLLECTION_EXIT_CODE} -ne 0 ]; then
          echo "‚ö†Ô∏è  Layer metrics collection had errors but continuing..."
        fi
        
        if [ -f "$LAYER_METRICS_FILE" ]; then
          echo ""
          echo "‚úÖ Layer metrics collected successfully"
          echo "üìÑ Layer metrics file: $LAYER_METRICS_FILE"
          echo "üìè File size: $(du -h "$LAYER_METRICS_FILE" | cut -f1)"
          echo ""
          
          # Show detailed summary
          if command -v jq &> /dev/null; then
            TOTAL_LAYERS=$(jq -r '.total_layers // 0' "$LAYER_METRICS_FILE")
            TOTAL_SIZE=$(jq -r '.total_size_bytes // 0' "$LAYER_METRICS_FILE")
            TOTAL_SIZE_HUMAN=$(numfmt --to=iec-i --suffix=B ${TOTAL_SIZE} 2>/dev/null || echo "${TOTAL_SIZE} bytes")
            
            echo "üìä Summary:"
            echo "  Total layers: ${TOTAL_LAYERS}"
            echo "  Total size: ${TOTAL_SIZE_HUMAN}"
            echo ""
            
            # Show top 5 largest layers
            echo "üîù Top 5 largest layers:"
            jq -r '.layers | sort_by(-.size_bytes) | .[:5] | .[] | "  Layer \(.layer_index): \(.size_human) - \(.created_by[:80])"' "$LAYER_METRICS_FILE" 2>/dev/null || echo "  Could not parse layer data"
          else
            echo "üìä jq not available, skipping detailed summary"
          fi
        else
          echo ""
          echo "‚ö†Ô∏è  Layer metrics file not created: $LAYER_METRICS_FILE"
          echo "This is not critical, continuing..."
        fi
        
        echo ""
        echo "‚úÖ Layer metrics collection completed"
        echo "=========================================="

    # Upload job-specific build metrics as artifact
    - name: Upload Build Metrics
      uses: actions/upload-artifact@v4
      with:
        name: build-metrics-${{ inputs.framework }}-${{ env.PLATFORM_ARCH }}-${{ github.run_id }}-${{ job.check_run_id }}
        path: build-metrics/metrics-${{ inputs.framework }}-${{ env.PLATFORM_ARCH }}-${{ github.run_id }}-${{ job.check_run_id }}.json
        retention-days: 7

    # Upload layer metrics as artifact
    - name: Upload Layer Metrics
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: layer-metrics-${{ inputs.framework }}-${{ env.PLATFORM_ARCH }}-${{ github.run_id }}-${{ job.check_run_id }}
        path: build-metrics/layers/layer-metrics-${{ inputs.framework }}-${{ env.PLATFORM_ARCH }}-${{ github.run_id }}-${{ job.check_run_id }}.json
        retention-days: 7

    # Upload build logs as artifact for debugging and analysis
    - name: Upload Build Logs
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: build-logs-${{ inputs.framework }}-${{ env.PLATFORM_ARCH }}-${{ github.run_id }}-${{ job.check_run_id }}
        path: build-logs/*.log
        retention-days: 7
