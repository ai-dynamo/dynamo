# Workflow Metrics Uploader - Error Classification Integration

## Summary

Successfully integrated AI error classification into `workflow_metrics_uploader.py`. Now when uploading job and step metrics to OpenSearch, failed jobs/steps automatically get classified with three new fields:

- `s_error_type` - Error category (e.g., "infrastructure_error", "timeout")
- `s_error_summary` - Root cause summary from AI
- `f_error_confidence` - Classification confidence (0.0-1.0)

## Changes Made

### 1. Modified `workflow_metrics_uploader.py`

**Added imports** (lines 11-18):
```python
from error_classification.classifier import ErrorClassifier
from error_classification.error_extractor import ErrorExtractor
from error_classification.config import Config as ErrorConfig
```

**Added field constants** (lines 28-31):
```python
FIELD_ERROR_TYPE = "s_error_type"
FIELD_ERROR_SUMMARY = "s_error_summary"
FIELD_ERROR_CONFIDENCE = "f_error_confidence"
```

**Modified `__init__`** (lines 103-130):
- Initialize error classifier if `ENABLE_ERROR_CLASSIFICATION="true"`
- Create `ErrorClassifier` and `ErrorExtractor` instances
- Handle graceful fallback if classification unavailable

**Added `add_error_classification_fields()` method** (lines 525-599):
- Checks if job/step has failed status
- Fetches job logs from GitHub API
- Extracts error messages
- Classifies with Claude API
- Adds three fields to metrics dictionary

**Modified `upload_job_metrics()`** (lines 800-807):
- Added call to `add_error_classification_fields()` for failed jobs

**Modified `upload_step_metrics()`** (lines 867-874):
- Added call to `add_error_classification_fields()` for failed steps

## How to Use

### Enable Error Classification

Set environment variables:

```bash
export ENABLE_ERROR_CLASSIFICATION="true"
export ANTHROPIC_API_KEY="your-nvidia-api-key"
export API_FORMAT="openai"
export API_BASE_URL="https://inference-api.nvidia.com/v1"
export ANTHROPIC_MODEL="aws/anthropic/claude-opus-4-5"
```

### Run Workflow Metrics Uploader

```bash
cd opensearch_upload
python3 workflow_metrics_uploader.py
```

### Expected Output

For failed jobs, you'll see:

```
üìã Processing workflow: CI Test Suite (ID: 21689681963)
  üì§ Processing job: vllm-build-test (cuda12.9, amd64)
   üìä Job annotations: 2 total, 1 failures, 0 warnings
   ü§ñ Classifying error for job: vllm-build-test (cuda12.9, amd64)
   ‚úÖ Classified as: infrastructure_error (92% confidence)
      Summary: This is a pytest collection error where the test module fails to import...
   ‚úÖ Posted metrics for github-job-12345678-attempt-1
```

## OpenSearch Fields

### Jobs Index

Failed jobs now include:

```json
{
  "_id": "github-job-12345678-attempt-1",
  "s_job_name": "vllm-build-test (cuda12.9, amd64)",
  "s_status": "failure",
  "l_status_number": 1,

  // NEW FIELDS:
  "s_error_type": "infrastructure_error",
  "s_error_summary": "This is a pytest collection error where the test module fails to import due to missing dependencies...",
  "f_error_confidence": 0.92,

  // ... other existing fields ...
}
```

### Steps Index

Failed steps include the same three fields:

```json
{
  "_id": "github-step-12345678_5-attempt-1",
  "s_step_name": "Run tests",
  "s_status": "failure",

  // NEW FIELDS:
  "s_error_type": "infrastructure_error",
  "s_error_summary": "Test environment missing required dependencies...",
  "f_error_confidence": 0.92,

  // ... other existing fields ...
}
```

## Querying Classified Errors

### Find all infrastructure errors

```bash
GET /jobs/_search
{
  "query": {
    "term": { "s_error_type": "infrastructure_error" }
  }
}
```

### Aggregate errors by type

```bash
GET /jobs/_search
{
  "size": 0,
  "aggs": {
    "error_distribution": {
      "terms": {
        "field": "s_error_type",
        "size": 10
      }
    }
  }
}
```

### Find high-confidence failures

```bash
GET /jobs/_search
{
  "query": {
    "bool": {
      "must": [
        { "term": { "s_status": "failure" } },
        { "range": { "f_error_confidence": { "gte": 0.8 } } }
      ]
    }
  }
}
```

### Get error summary for specific workflow

```bash
GET /jobs/_search
{
  "query": {
    "term": { "s_workflow_id": "21689681963" }
  },
  "_source": ["s_job_name", "s_error_type", "s_error_summary", "f_error_confidence"]
}
```

## Error Categories

The system classifies into 10 categories:

1. **dependency_error** - Package installation, version conflicts, missing libraries
2. **timeout** - Test/build timeouts, deadlocks, hung processes
3. **resource_exhaustion** - Out of Memory (CPU/GPU), disk full, resource limits
4. **network_error** - Connection failures, DNS issues, download failures
5. **assertion_failure** - Test assertion failures, validation errors
6. **compilation_error** - Build/compile failures, linking errors
7. **runtime_error** - Crashes, segfaults, uncaught exceptions
8. **infrastructure_error** - GitHub Actions, Docker, K8s issues, pytest collection errors
9. **configuration_error** - Invalid configs, env variables, permissions
10. **flaky_test** - Non-deterministic failures, race conditions

## Testing

### Unit Test

```bash
cd opensearch_upload
python3 test_metrics_classification.py
```

### Integration Test with Real Data

```bash
# Set environment variables
export ENABLE_ERROR_CLASSIFICATION="true"
export ANTHROPIC_API_KEY="your-key"
export WORKFLOW_INDEX="https://your-opensearch:9200/workflows"
export JOB_INDEX="https://your-opensearch:9200/jobs"
export STEPS_INDEX="https://your-opensearch:9200/steps"
export GITHUB_TOKEN="your-github-token"
export REPO="ai-dynamo/dynamo"
export HOURS_BACK="1"

# Run uploader on recent failures
python3 workflow_metrics_uploader.py
```

### Verify in OpenSearch

```bash
# Check if error fields are present
GET /jobs/_search
{
  "query": {
    "exists": { "field": "s_error_type" }
  },
  "size": 10
}
```

## Cost Optimization

The integration implements several cost-saving features:

- **Prompt Caching**: System prompt cached for 5 minutes (90% cost reduction)
- **Error Deduplication**: Similar errors classified once (70-90% reduction)
- **Selective Processing**: Only failed jobs/steps classified
- **Batch Mode**: Efficient batch processing for historical data

**Expected Costs:**
- ~$0.003-0.005 per error classified
- With optimizations: ~$3-5/month for typical usage

## Troubleshooting

### Classification not running

**Symptoms**: No "ü§ñ Classifying error" messages in output

**Solutions**:
1. Check `ENABLE_ERROR_CLASSIFICATION="true"` is set
2. Verify `ANTHROPIC_API_KEY` is set
3. Look for "‚úÖ Error classification enabled" at startup
4. Check for import errors in output

### Classification fails

**Symptoms**: "‚ö†Ô∏è Error during classification" in output

**Solutions**:
1. Verify API key is valid
2. Check API endpoint is accessible
3. Confirm GitHub token has permissions to fetch logs
4. Review error extraction patterns

### Low confidence scores

**Symptoms**: Confidence < 70% frequently

**Solutions**:
- This is normal for ambiguous errors
- System automatically re-analyzes with more context
- Review log extraction to ensure capturing full error

### No errors extracted

**Symptoms**: "‚ö†Ô∏è No errors extracted from job logs"

**Solutions**:
- Verify logs are available via GitHub API
- Check error extraction patterns match your log format
- Review `error_extractor.py` patterns

## Disable Classification

To disable without removing code:

```bash
unset ENABLE_ERROR_CLASSIFICATION
# OR
export ENABLE_ERROR_CLASSIFICATION="false"
```

The uploader will work normally without classification.

## Future Enhancements

1. **Deduplication Storage**: Store classifications in OpenSearch to reuse for identical errors
2. **Suggested Fixes**: Add remediation suggestions to classification results
3. **Custom Categories**: Allow project-specific error categories
4. **Batch Reclassification**: Reclassify historical failures with improved model
5. **Confidence Thresholds**: Skip classification for errors below confidence threshold
6. **Error Grouping**: Group similar errors across multiple jobs

## Files

- `workflow_metrics_uploader.py` - Main integration (modified)
- `ERROR_CLASSIFICATION_INTEGRATION.md` - Detailed user guide
- `test_metrics_classification.py` - Integration test script
- `METRICS_UPLOADER_INTEGRATION.md` - This file
