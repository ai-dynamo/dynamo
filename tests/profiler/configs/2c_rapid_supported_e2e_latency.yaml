# Case 2c: AIC supported model, rapid, without planner, e2eLatency instead of ttft/itl
model: "Qwen/Qwen3-32B"
backend: trtllm
image: "nvcr.io/nvidia/dynamo:latest"
hardware:
  gpuSku: h200_sxm
  totalGpus: 64
  numGpusPerNode: 8
workload:
  isl: 4000
  osl: 1000
  requestRate: 5.0
sla:
  e2eLatency: 35000.0
searchStrategy: rapid
