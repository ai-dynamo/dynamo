# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# DeepSeek-R1 (FP4) with vLLM â€” Disaggregated Prefill/Decode on 16x GB200
#
# Architecture: 4 GB200 nodes (4 GPUs each), 16 GPUs total
#   - Prefill: 8 GPUs (2 nodes), DP+EP with AllGather-ReduceScatter (MNNVL-native)
#   - Decode:  8 GPUs (2 nodes), DP+EP with AllGather-ReduceScatter (MNNVL-native)
#
# Uses NVIDIA's FP4-quantized DeepSeek-R1 checkpoint for native Blackwell
# FP4 tensor core support. Achieves ~26K prefill TPGS and ~10K decode TPGS.
#
# Prerequisites:
#   - 4x GB200 nodes with NVLink-C2C connectivity
#   - Model weights downloaded to PVC at /model-cache/deepseek-r1-fp4
#     (use recipes/deepseek-r1/model-cache/ to provision)

# ComputeDomain provides IMEX channel access for MNNVL (multi-node NVLink)
# numNodes = total nodes across all workers (prefill + decode nodeCount)
apiVersion: resource.nvidia.com/v1beta1
kind: ComputeDomain
metadata:
  name: vllm-dsr1-gb200-compute-domain
spec:
  numNodes: 4
  channel:
    resourceClaimTemplate:
      name: vllm-dsr1-gb200-compute-domain-channel
---

apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: vllm-dsr1-gb200
spec:
  backendFramework: vllm
  pvcs:
    - name: model-cache
      create: false
  services:
    Frontend:
      componentType: frontend
      replicas: 1
      volumeMounts:
        - name: model-cache
          mountPoint: /model-cache
      extraPodSpec:
        containers: []
        imagePullSecrets:
          - name: nvcr-pull-secret
        tolerations:
          - key: "dedicated"
            operator: "Equal"
            value: "user-workload"
            effect: "NoSchedule"
          - key: "dedicated"
            operator: "Equal"
            value: "user-workload"
            effect: "NoExecute"
        mainContainer:
          startupProbe:
            httpGet:
              path: /health
              port: 8000
            periodSeconds: 10
            timeoutSeconds: 1800
            failureThreshold: 60
          image: nvcr.io/nvidian/dynamo-dev/dynamo-vllm:vllm-32693db-cu13
    decode:
      componentType: worker
      subComponentType: decode
      replicas: 1
      multinode:
        nodeCount: 2
      livenessProbe:
        httpGet:
          path: /live
          port: 9090
        periodSeconds: 30
        timeoutSeconds: 30
        failureThreshold: 100
      resources:
        requests:
          cpu: "130"
          memory: "850Gi"
        limits:
          cpu: "130"
          memory: "850Gi"
          gpu: "4"
        claims:
          - name: compute-domain-channel
      volumeMounts:
        - name: model-cache
          mountPoint: /model-cache
      sharedMemory:
        size: 800Gi
      extraPodSpec:
        containers: []
        imagePullSecrets:
          - name: nvcr-pull-secret
        resourceClaims:
          - name: compute-domain-channel
            resourceClaimTemplateName: vllm-dsr1-gb200-compute-domain-channel
        tolerations:
          - key: "dedicated"
            operator: "Equal"
            value: "user-workload"
            effect: "NoSchedule"
          - key: "dedicated"
            operator: "Equal"
            value: "user-workload"
            effect: "NoExecute"
        mainContainer:
          startupProbe:
            httpGet:
              path: /health
              port: 9090
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 600
          image: nvcr.io/nvidian/dynamo-dev/dynamo-vllm:vllm-32693db-cu13
          workingDir: /workspace/dynamo
          env:
            # --- System / NCCL ---
            - name: NVIDIA_GDRCOPY
              value: "1"
            - name: NVSHMEM_IB_ENABLE_IBGDA
              value: "1"
            - name: VLLM_SKIP_P2P_CHECK
              value: "1"
            - name: NCCL_CUMEM_ENABLE
              value: "1"
            - name: NCCL_MNNVL_ENABLE
              value: "1"
            - name: NCCL_NVLS_ENABLE
              value: "1"
            - name: NCCL_DEBUG
              value: "WARN"
            - name: NCCL_TIMEOUT
              value: "1800"
            - name: TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC
              value: "1800"
            - name: GLOO_SOCKET_IFNAME
              value: eth0
            # --- Blackwell FP4 kernel optimizations ---
            - name: VLLM_USE_FLASHINFER_MOE_FP4
              value: "1"
            - name: VLLM_FLASHINFER_MOE_BACKEND
              value: latency
            - name: VLLM_USE_NCCL_SYMM_MEM
              value: "1"
            - name: VLLM_RANDOMIZE_DP_DUMMY_INPUTS
              value: "1"
            - name: VLLM_ENABLE_FUSED_MOE_ACTIVATION_CHUNKING
              value: "0"
            # --- Decode-specific optimizations ---
            - name: VLLM_LOG_STATS_INTERVAL
              value: "1"
            - name: VLLM_MLA_FP8_PROJ
              value: "1"
            - name: VLLM_DEEPEP_LOW_LATENCY_ALLOW_NVLINK
              value: "1"
            - name: VLLM_DEEPEP_LOW_LATENCY_USE_MNNVL
              value: "1"
            - name: VLLM_DEEPEP_BUFFER_SIZE_MB
              value: "0"
            - name: VLLM_EP_USE_SBO
              value: "0"
            - name: VLLM_MOE_DP_CHUNK_SIZE
              value: "1024"
            - name: VLLM_DEEPEPLL_NVFP4_DISPATCH
              value: "1"
            - name: VLLM_V1_OUTPUT_PROC_CHUNK_SIZE
              value: "2048"
          command:
            - /bin/bash
            - -c
          args:
            - |-
              python3 -m dynamo.vllm \
                --model /model-cache/deepseek-r1-fp4 \
                --served-model-name deepseek-ai/DeepSeek-R1 \
                --data-parallel-size 8 \
                --kv-cache-dtype fp8 \
                --enable-expert-parallel \
                --attention-config.backend FLASHINFER_MLA \
                --attention-config.use_trtllm_ragged_deepseek_prefill=true \
                --max-model-len 2148 \
                --trust-remote-code \
                --all2all-backend allgather_reducescatter \
                --data-parallel-hybrid-lb \
                --compilation_config.custom_ops+=+rms_norm,+rotary_embedding \
                --async-scheduling \
                --compilation-config '{"cudagraph_mode":"FULL_DECODE_ONLY"}' \
                --stream-interval 50 \
                --max-num-seqs 1024 \
                --max-num-batched-tokens 1024 \
                --cudagraph-capture-sizes 128 512 1024 \
                --kv-transfer-config '{"kv_connector":"NixlConnector","kv_role":"kv_both","kv_load_failure_policy":"fail"}'
                # --no-enable-prefix-caching \
                # --kv-transfer-config '{"kv_connector":"DecodeBenchConnector","kv_role":"kv_both"}'

    prefill:
      componentType: worker
      subComponentType: prefill
      replicas: 2
      livenessProbe:
        httpGet:
          path: /live
          port: 9090
        periodSeconds: 30
        timeoutSeconds: 30
        failureThreshold: 100
      resources:
        requests:
          cpu: "130"
          memory: "850Gi"
        limits:
          cpu: "130"
          memory: "850Gi"
          gpu: "4"
        claims:
          - name: compute-domain-channel
      volumeMounts:
        - name: model-cache
          mountPoint: /model-cache
      sharedMemory:
        size: 800Gi
      extraPodSpec:
        containers: []
        imagePullSecrets:
          - name: nvcr-pull-secret
        resourceClaims:
          - name: compute-domain-channel
            resourceClaimTemplateName: vllm-dsr1-gb200-compute-domain-channel
        tolerations:
          - key: "dedicated"
            operator: "Equal"
            value: "user-workload"
            effect: "NoSchedule"
          - key: "dedicated"
            operator: "Equal"
            value: "user-workload"
            effect: "NoExecute"
        mainContainer:
          startupProbe:
            httpGet:
              path: /health
              port: 9090
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 600
          image: nvcr.io/nvidian/dynamo-dev/dynamo-vllm:vllm-32693db-cu13
          workingDir: /workspace/dynamo
          env:
            # --- System / NCCL ---
            - name: NVIDIA_GDRCOPY
              value: "1"
            - name: NVSHMEM_IB_ENABLE_IBGDA
              value: "1"
            - name: VLLM_SKIP_P2P_CHECK
              value: "1"
            - name: NCCL_CUMEM_ENABLE
              value: "1"
            - name: NCCL_MNNVL_ENABLE
              value: "1"
            - name: NCCL_NVLS_ENABLE
              value: "1"
            - name: NCCL_DEBUG
              value: "WARN"
            - name: NCCL_TIMEOUT
              value: "1800"
            - name: TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC
              value: "1800"
            - name: GLOO_SOCKET_IFNAME
              value: eth0
            # --- Blackwell FP4 kernel optimizations ---
            - name: VLLM_USE_FLASHINFER_MOE_FP4
              value: "1"
            - name: VLLM_FLASHINFER_MOE_BACKEND
              value: latency
            - name: VLLM_USE_NCCL_SYMM_MEM
              value: "1"
            - name: VLLM_RANDOMIZE_DP_DUMMY_INPUTS
              value: "1"
            - name: VLLM_ENABLE_FUSED_MOE_ACTIVATION_CHUNKING
              value: "0"
            # --- Prefill-specific optimizations ---
            - name: VLLM_ENABLE_MOE_DP_CHUNK
              value: "0"
          command:
            - /bin/bash
            - -c
          args:
            - |-
              python3 -m dynamo.vllm \
                --model /model-cache/deepseek-r1-fp4 \
                --served-model-name deepseek-ai/DeepSeek-R1 \
                --data-parallel-size 4 \
                --kv-cache-dtype fp8 \
                --enable-expert-parallel \
                --attention-config.backend FLASHINFER_MLA \
                --attention-config.use_trtllm_ragged_deepseek_prefill=true \
                --max-model-len 2148 \
                --trust-remote-code \
                --all2all-backend allgather_reducescatter \
                --data-parallel-rpc-port 13345 \
                --disable-custom-all-reduce \
                --disable-nccl-for-dp-synchronization \
                --no-enable-prefix-caching \
                --async-scheduling \
                --gpu-memory-utilization 0.85 \
                --max-num-batched-tokens 65536 \
                --max-num-seqs 1024 \
                --swap-space 16 \
                --enforce-eager \
                --kv-transfer-config '{"kv_connector":"NixlConnector","kv_role":"kv_both","kv_load_failure_policy":"fail"}'
                # --no-enable-prefix-caching
                # --offload-group-size 2 \
                # --offload-num-in-group 1 \
                # --offload-prefetch-step 1
