apiVersion: v1
data:
  decode_raw_data.json: '{"x_kv_usage": [0.0013671875, 0.117578125, 0.2337890625,
    0.35, 0.4662109375, 0.582421875, 0.02770703125, 0.19394921875, 0.3878984375],
    "y_context_length": [350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 7093.0, 7093.0,
    7093.0], "z_itl": [22.328989559118238, 28.930944401477372, 39.79771755353983,
    50.22440618049955, 66.54923459997094, 81.3827169924877, 22.952935759519036, 26.22996563068995,
    28.90201610807329], "z_thpt_per_gpu": [44.68861568380151, 2940.915255357205, 4243.415968515759,
    5012.188946852754, 5040.085347797445, 5127.196771247916, 43.44732661480929, 265.7791016799465,
    482.0421085787754], "max_kv_tokens": 256000}'
  prefill_raw_data.json: '{"prefill_isl": [100, 2621, 5142, 7663, 10184, 12705, 15226,
    17747, 20268, 22789, 25310, 27831, 30352, 32873], "prefill_ttft": [46.813452999999996,
    274.17285599999997, 545.795075, 836.529149, 1160.039976, 1512.917027, 1874.521006,
    2256.2636279999997, 2689.089398, 3100.656301, 3572.080486, 3993.552093, 4494.880741,
    5122.121039], "prefill_thpt_per_gpu": [2136.138088339692, 9559.662609343064, 9421.118356555344,
    9160.46979254754, 8779.007802055263, 8397.684587629405, 8122.608363024127, 7865.658861740071,
    7537.12391082061, 7349.734310329805, 7085.506639393231, 6968.983839921079, 6752.570701853021,
    6417.849119476851]}'
kind: ConfigMap
metadata:
  name: planner-profile-data
---
apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: vllm-disagg
spec:
  services:
    Frontend:
      componentType: frontend
      dynamoNamespace: vllm-disagg
      extraPodSpec:
        mainContainer:
          args: null
          command: null
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.6.1
          workingDir: null
      replicas: 1
      resources: null
      subComponentType: null
    Planner:
      componentType: planner
      dynamoNamespace: vllm-disagg
      extraPodSpec:
        mainContainer:
          args:
          - --backend=vllm
          - --itl=50
          - --ttft=500
          - --adjustment-interval=180
          - --environment=kubernetes
          - --load-prediction-window-size=50
          - --load-predictor=arima
          - --max-gpu-budget=8
          - --min-endpoint=1
          - --prometheus-port=0
          - --namespace=vllm-disagg
          - --prefill-engine-num-gpu=1
          - --decode-engine-num-gpu=1
          - --profile-results-dir=/workspace/profiling_results
          command:
          - python3
          - -m
          - planner_sla
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.6.1
          volumeMounts:
          - mountPath: /workspace/profiling_results
            name: planner-profile-data
            readOnly: true
          workingDir: /workspace/components/src/dynamo/planner
        volumes:
        - configMap:
            name: planner-profile-data
          name: planner-profile-data
      replicas: 1
    VllmDecodeWorker:
      componentType: worker
      dynamoNamespace: vllm-disagg
      envFromSecret: hf-token-secret
      extraPodSpec:
        mainContainer:
          args:
          - --model
          - Qwen/Qwen3-32B
          - --is-decode-worker
          - --tensor-parallel-size
          - '1'
          command:
          - python3
          - -m
          - dynamo.vllm
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.6.1
          workingDir: /workspace/examples/backends/vllm
      replicas: 1
      resources:
        limits:
          gpu: '1'
        requests:
          gpu: '1'
      subComponentType: decode
    VllmPrefillWorker:
      componentType: worker
      dynamoNamespace: vllm-disagg
      envFromSecret: hf-token-secret
      extraPodSpec:
        mainContainer:
          args:
          - --model
          - Qwen/Qwen3-32B
          - --is-prefill-worker
          - --tensor-parallel-size
          - '1'
          command:
          - python3
          - -m
          - dynamo.vllm
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.6.1
          workingDir: /workspace/examples/backends/vllm
      replicas: 1
      resources:
        limits:
          gpu: '1'
        requests:
          gpu: '1'
      subComponentType: prefill
