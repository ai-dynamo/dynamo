apiVersion: workloads.x-k8s.io/v1alpha1
kind: RoleBasedGroup
metadata:
  name: dynamo-pd
spec:
  roleTemplate:
    - name: dynamo-common
      template:
        spec:
          volumes:
            - name: model
              persistentVolumeClaim:
                claimName: qwen3-235b
          containers:
            - env:
                - name: ETCD_ENDPOINTS
                  value: http://etcd:2379
                - name: NATS_SERVER
                  value: nats://nats:4222
                - name: DYNAMO_RP_TIMEOUT
                  value: "60"
              image: nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.7.1
              name: main
              volumeMounts:
                - name: model
                  mountPath: /models/qwen3-235B
  roles:
    - name: frontend
      replicas: 1
      templateRef:
        name: dynamo-common
      templatePatch:
        spec:
          containers:
            - command:
                - python
                - -m
                - dynamo.frontend
                - --http-port 8000
                - --model-path
                - /models/qwen3-235B/
                - --model-name
                - qwen3-32B
                - --namespace=dynamo
              name: main
              ports:
                - containerPort: 8000
                  name: http
                  protocol: TCP
              readinessProbe:
                initialDelaySeconds: 30
                periodSeconds: 30
                tcpSocket:
                  port: 8000
    - name: engine
      replicas: 1
      templateRef:
        name: dynamo-common
      templatePatch:
        spec:
          volumes:
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 100Gi
          containers:
            - command:
                - python3
                - -m
                - dynamo.sglang
                - --model-path
                - /models/qwen3-235B/
                - --served-model-name
                - qwen3-235B
                - --host
                - "0.0.0.0"
                - --tp-size
                - "4"
              name: main
              volumeMounts:
                - mountPath: /dev/shm
                  name: dshm
              resources:
                limits:
                  nvidia.com/gpu: "4"
                requests:
                  nvidia.com/gpu: "4"