# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# Disaggregated mocker deployment for testing --throughput-metrics-source=router
# on a cluster WITHOUT kube-prometheus-stack PodMonitor CRDs.
#
# Uses nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.9.0 as the base image and
# patches the planner Python files via a ConfigMap + cp-at-startup approach.
#
# Prerequisites:
#   1. standalone-prometheus.yaml deployed in the same namespace
#   2. planner-patches ConfigMap applied (see planner-patches-cm.yaml)
#
# Deploy:
#   NS=darfeen-dynamo-cloud
#   kubectl apply -f planner-patches-cm.yaml -n $NS
#   kubectl apply -f standalone-prometheus.yaml -n $NS
#   kubectl apply -f nebius-router-metrics-test.yaml -n $NS
#
# Watch planner observe router metrics and make scaling decisions:
#   kubectl logs -n $NS -l nvidia.com/dynamo-component-type=planner -f \
#     | grep -E "Observed|scaling|replicas|throughput|router"
#
# Verify Prometheus is scraping the router:
#   kubectl port-forward svc/prometheus 9090:9090 -n $NS &
#   curl -s 'http://localhost:9090/api/v1/query' \
#     --data-urlencode 'query=dynamo_component_router_requests_total' | python3 -m json.tool

apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: mocker-router-metrics-test
spec:
  services:
    Frontend:
      componentType: frontend
      replicas: 1
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.9.0

    Planner:
      componentType: planner
      replicas: 1
      extraPodSpec:
        volumes:
          - name: planner-patches
            configMap:
              name: planner-patches
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.9.0
          command:
            - bash
            - -c
            - |
              set -e
              SP=/opt/dynamo/venv/lib/python3.12/site-packages
              echo "Applying planner patches..."
              cp /patches/prometheus.py       $SP/dynamo/planner/utils/prometheus.py
              cp /patches/planner_argparse.py $SP/dynamo/planner/utils/planner_argparse.py
              cp /patches/planner_core.py     $SP/dynamo/planner/utils/planner_core.py
              cp /patches/defaults.py         $SP/dynamo/planner/defaults.py
              cp /patches/prometheus_names.py $SP/dynamo/prometheus_names.py
              echo "Patches applied. Starting planner..."
              exec python3 -m dynamo.planner.planner_sla \
                --environment=kubernetes \
                --backend=mocker \
                --adjustment-interval=30 \
                --ttft=2000 \
                --itl=200 \
                --max-gpu-budget=-1 \
                --no-correction \
                --profile-results-dir=/workspace/tests/planner/profiling_results/H200_TP1P_TP1D \
                --metric-pulling-prometheus-endpoint=http://prometheus:9090 \
                --throughput-metrics-source=router
          volumeMounts:
            - name: planner-patches
              mountPath: /patches

    prefill:
      componentType: worker
      subComponentType: prefill
      replicas: 1
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.9.0
          workingDir: /workspace
          command:
            - python3
            - -m
            - dynamo.mocker
          args:
            - --model-path
            - nvidia/Llama-3.1-8B-Instruct-FP8
            - --model-name
            - nvidia/Llama-3.1-8B-Instruct-FP8
            # run 5x faster than wall-clock so the planner sees meaningful traffic quickly
            - --speedup-ratio
            - "5.0"
            - --planner-profile-data
            - /workspace/tests/planner/profiling_results/H200_TP1P_TP1D
            - --is-prefill-worker

    decode:
      componentType: worker
      subComponentType: decode
      replicas: 1
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.9.0
          workingDir: /workspace
          command:
            - python3
            - -m
            - dynamo.mocker
          args:
            - --model-path
            - nvidia/Llama-3.1-8B-Instruct-FP8
            - --model-name
            - nvidia/Llama-3.1-8B-Instruct-FP8
            - --speedup-ratio
            - "5.0"
            - --planner-profile-data
            - /workspace/tests/planner/profiling_results/H200_TP1P_TP1D
            - --is-decode-worker
