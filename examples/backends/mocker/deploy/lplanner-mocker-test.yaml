# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

# E2E test for single-DGD disagg setup with a local SLA Planner.
#
# Architecture: one DGD containing everything.
#   Frontend (round-robin, built-in router) → MockerPrefill (subComponentType: prefill)
#                                            → MockerDecode  (subComponentType: decode)
#   SLA Planner (environment=kubernetes) scales workers directly via K8s API,
#   reads throughput metrics from cluster Prometheus (frontend histograms,
#   throughput_metrics_source=frontend).
#
# Note: in this single-DGD setup the router is embedded in the frontend process.
# There is no separate Router component; throughput_metrics_source=router is only
# used in hierarchical setups where explicit LocalRouter pods are deployed.
#
# Image: CI-built from main, has runtime.endpoint() + PlannerConfig.
# Self-patch applies only branch-specific changes:
#   - prometheus_names.py
#   - planner/defaults.py
#   - planner/utils/planner_config.py
#   - planner/utils/prometheus.py
#   - planner/utils/planner_core.py
#
# Prerequisites (already deployed):
#   kubectl apply -f standalone-prometheus.yaml -n darfeen-dynamo-cloud
#
# Deploy:
#   kubectl apply -f lplanner-mocker-test.yaml -n darfeen-dynamo-cloud
#
# Watch planner read frontend metrics:
#   kubectl logs -n darfeen-dynamo-cloud \
#     $(kubectl get pods -n darfeen-dynamo-cloud -l nvidia.com/dynamo-component-type=planner \
#       -o jsonpath='{.items[0].metadata.name}') -f \
#     | grep -E "Observed|adjustment interval"
#
# Send load:
#   ./send_load.sh darfeen-dynamo-cloud lp
#
# Cleanup:
#   kubectl delete -f lplanner-mocker-test.yaml -n darfeen-dynamo-cloud

apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: lp
spec:
  services:
    Frontend:
      componentType: frontend
      replicas: 1
      extraPodSpec:
        imagePullSecrets:
          - name: docker-imagepullsecret
        mainContainer:
          image: dynamoci.azurecr.io/ai-dynamo/dynamo:e95d0f99167fd9041b4083a3458044d588f95a37-vllm-cuda12-amd64
          workingDir: /workspace
          command:
            - python3
            - -m
            - dynamo.frontend
          args:
            - --router-mode
            - round-robin
            - --namespace
            - darfeen-dynamo-cloud-lp
            - --model-name
            - nvidia/Llama-3.1-8B-Instruct-FP8

    MockerPrefill:
      componentType: worker
      subComponentType: prefill
      replicas: 1
      extraPodSpec:
        imagePullSecrets:
          - name: docker-imagepullsecret
        mainContainer:
          image: dynamoci.azurecr.io/ai-dynamo/dynamo:e95d0f99167fd9041b4083a3458044d588f95a37-vllm-cuda12-amd64
          workingDir: /workspace
          command:
            - python3
            - -m
            - dynamo.mocker
          args:
            - --model-path
            - nvidia/Llama-3.1-8B-Instruct-FP8
            - --model-name
            - nvidia/Llama-3.1-8B-Instruct-FP8
            - --speedup-ratio
            - "5.0"
            - --planner-profile-data
            - /workspace/tests/planner/profiling_results/H200_TP1P_TP1D
            - --is-prefill-worker

    MockerDecode:
      componentType: worker
      subComponentType: decode
      replicas: 1
      extraPodSpec:
        imagePullSecrets:
          - name: docker-imagepullsecret
        mainContainer:
          image: dynamoci.azurecr.io/ai-dynamo/dynamo:e95d0f99167fd9041b4083a3458044d588f95a37-vllm-cuda12-amd64
          workingDir: /workspace
          command:
            - python3
            - -m
            - dynamo.mocker
          args:
            - --model-path
            - nvidia/Llama-3.1-8B-Instruct-FP8
            - --model-name
            - nvidia/Llama-3.1-8B-Instruct-FP8
            - --speedup-ratio
            - "5.0"
            - --planner-profile-data
            - /workspace/tests/planner/profiling_results/H200_TP1P_TP1D

    Planner:
      componentType: planner
      replicas: 1
      extraPodSpec:
        imagePullSecrets:
          - name: docker-imagepullsecret
        mainContainer:
          image: dynamoci.azurecr.io/ai-dynamo/dynamo:e95d0f99167fd9041b4083a3458044d588f95a37-vllm-cuda12-amd64
          command:
            - bash
            - -c
            - |
              set -e
              SP=/opt/dynamo/venv/lib/python3.12/site-packages
              echo "Cloning feat/throughput-metrics-source for SLA Planner patch..."
              git clone --depth=1 \
                --branch feat/throughput-metrics-source \
                https://github.com/ai-dynamo/dynamo /tmp/dynamo-pr 2>&1 | tail -3
              SRC_LIB=/tmp/dynamo-pr/lib/bindings/python/src/dynamo
              SRC_COMP=/tmp/dynamo-pr/components/src/dynamo
              echo "Patching: throughput_metrics_source support..."
              cp $SRC_LIB/prometheus_names.py                       $SP/dynamo/prometheus_names.py
              cp $SRC_COMP/planner/defaults.py                      $SP/dynamo/planner/defaults.py
              cp $SRC_COMP/planner/utils/planner_config.py          $SP/dynamo/planner/utils/planner_config.py
              cp $SRC_COMP/planner/utils/prometheus.py              $SP/dynamo/planner/utils/prometheus.py
              cp $SRC_COMP/planner/utils/planner_core.py            $SP/dynamo/planner/utils/planner_core.py
              echo "Patches applied. Starting SLA Planner kubernetes mode..."
              exec python3 -m dynamo.planner --config \
                '{"environment":"kubernetes","backend":"mocker","mode":"disagg","throughput_metrics_source":"frontend","throughput_adjustment_interval":30,"ttft":2000,"itl":200,"max_gpu_budget":-1,"prefill_engine_num_gpu":1,"decode_engine_num_gpu":1,"no_correction":true,"profile_results_dir":"/workspace/tests/planner/profiling_results/H200_TP1P_TP1D","metric_pulling_prometheus_endpoint":"http://prometheus:9090","model_name":"nvidia/Llama-3.1-8B-Instruct-FP8"}'
