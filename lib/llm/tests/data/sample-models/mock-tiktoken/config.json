{
  "model_type": "kimi",
  "max_position_embeddings": 32768,
  "architectures": ["KimiForCausalLM"],
  "eos_token_id": [370],
  "vocab_size": 375
}
