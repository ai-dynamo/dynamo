backend: pytorch
tensor_parallel_size: 8
pipeline_parallel_size: 1
enable_attention_dp: false
enable_chunked_prefill: false
max_batch_size: 12
max_num_tokens: 5512
max_seq_len: 5500
kv_cache_config:
  enable_block_reuse: true
  free_gpu_memory_fraction: 0.8
