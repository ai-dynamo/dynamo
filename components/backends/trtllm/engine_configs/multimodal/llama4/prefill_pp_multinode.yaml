pipeline_parallel_size: 2
tensor_parallel_size: 8
moe_expert_parallel_size: 1
enable_attention_dp: false
max_num_tokens: 8192
max_batch_size: 16
trust_remote_code: true
backend: pytorch
enable_chunked_prefill: true
# Overlap scheduler not currently supported in prefill only workers.
disable_overlap_scheduler: true

kv_cache_config:
  free_gpu_memory_fraction: 0.30
  enable_block_reuse: false

cache_transceiver_config:
  backend: DEFAULT